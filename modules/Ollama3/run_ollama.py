"""Wrapper per avviare modelli Ollama localmente."""

def run_model(prompt):
    return "ðŸ¦™ Risposta simulata da Ollama3"