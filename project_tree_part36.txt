Questa √® la parte 36 di project_tree. Continua da quella precedente.

            hud.css
            keyboard_dropdown.py
            mission_gui.py
        evolution/
            ai2ui_adapter.py
            auto_gpt.py
            gpt_engineer.py
            metagpt.py
        experience/
            __init__.py
            azr_analyzer.py
            experience_memory.py
        io_modules/
            mobile_connect.py
        llm/
            azr_reasoner.py
            chatgpt_interface.py
            gpt4o_validator.py
            ollama3_interface.py
        local/
            README.md
            github_sync.py
            huggingface_tools.py
            leon_ai_bridge.py
            localai_adapter.py
            n8n_connector.py
        messaging/
            __init__.py
            rabbitmq_messenger.py
        mobile/
            note_interface.py
        mobile_flutter/
            __init__.py
            flutter_bridge.py
        optional/
            elevenlabs_tts.py
            huggingface_tools.py
            n8n_connector.py
            plugin_manager.py
            vosk_stt.py
        sandbox_executor/
            secure_executor.py
        start_fullmode/
            initializer.py
        strategic/
            __init__.py
            strategic_brain.py
            strategic_runner.py
        stream_vision/
            __init__.py
            video_pipeline.py
        stream_voice/
            __init__.py
        vision_audio/
            __init__.py
            note10_jarvis_bridge.py
        voice_bridge/
            activation_hook.py
            audio_interface.py
            dia_model_mock.py
            multimodal_controller.py
            nari_dia_tts.py
            pyttsx3_tts.py
            speech_to_text.py
            text_to_speech.py
            tts_engine.py
            voice_loop.py
            whisper_interface.py
    monitoring/
        __init__.py
        health_check.py
        log_dashboard.py
        metrics_exporter.py
    node_modules/
        .package-lock.json
        @types/
            react/
                LICENSE
                README.md
                canary.d.ts
                compiler-runtime.d.ts
                experimental.d.ts
                global.d.ts
                index.d.ts
                jsx-dev-runtime.d.ts
                jsx-runtime.d.ts
                package.json
                ts5.0/
                    canary.d.ts
                    experimental.d.ts
                    global.d.ts
                    index.d.ts
                    jsx-dev-runtime.d.ts
                    jsx-runtime.d.ts
                    v18/
                        global.d.ts
                        index.d.ts
                        jsx-dev-runtime.d.ts
                        jsx-runtime.d.ts
                        ts5.0/
                            global.d.ts
                            index.d.ts
                            jsx-dev-runtime.d.ts
                            jsx-runtime.d.ts
        csstype/
            LICENSE
            README.md
            index.d.ts
            index.js.flow
            package.json
        react/
            LICENSE
            README.md
            compiler-runtime.js
            index.js
            jsx-dev-runtime.js
            jsx-dev-runtime.react-server.js
            jsx-runtime.js
            jsx-runtime.react-server.js
            package.json
            react.react-server.js
            cjs/
                react-compiler-runtime.development.js
                react-compiler-runtime.production.js
                react-compiler-runtime.profiling.js
                react-jsx-dev-runtime.development.js
                react-jsx-dev-runtime.production.js
                react-jsx-dev-runtime.profiling.js
                react-jsx-dev-runtime.react-server.development.js
                react-jsx-dev-runtime.react-server.production.js
                react-jsx-runtime.development.js
                react-jsx-runtime.production.js
                react-jsx-runtime.profiling.js
                react-jsx-runtime.react-server.development.js
                react-jsx-runtime.react-server.production.js
                react.development.js
                react.production.js
                react.react-server.development.js
                react.react-server.production.js
    orchestrator/
        __init__.py
        autonomy_controller.py
        genesis_orchestrator.py
        mission_controller.py
        multimodal_controller.py
        patch_scheduler.py
        real_life_controller.py
        router_integration.py
        sentient_mode.py
    personal_finance/
        __init__.py
        finance_tracker.py
    rag/
        insight_rag.py
    safety/
        __init__.py
        audit_logger.py
        human_override.py
        policies.yaml
        policy_manager.py
        safety_guard.py
    scheduler/
        auto_scheduler.py
        task_registry.py
    scripts/
        activate_hud_mobile.py
        aion_boot.py
        bootstrap_codex.py
        build_prompt.py
        mercurius_control.py
        prompt_panel.py
        start_genesis.py
        update_project_tree.py
    security/
        code_signer.py
        code_verifier.py
        gpg_support.py
        pairing_manager.py
    sensors/
        environment_analyzer.py
        sensor_hub.py
    src/
        mercurius-infinite/
    strategies/
        strategy_executor.py
    tests/
        conftest.py
        run_simulation.py
        test_agent_core.py
        test_audio_interface.py
        test_autonomia_cognitiva.py
        test_end2end.py
        test_initializer.py
        test_josch_bridge.py
        test_logger.py
        test_memory.py
        test_messaging.py
        test_modular_end2end.py
        test_multimodal.py
        test_neuro_learning.py
        test_orchestrator.py
        test_planner.py
        test_policy.py
        test_reasoner_dispatcher.py
        test_secure_executor.py
        test_supervisione.py
        test_task_manager_cli.py
        test_video_pipeline.py
    tools/
        conflict_inspector.py
        console.py
        feedback_collector.py
        live_logger.py
    trading/
        fin_gpt.py
        finrl_agent.py
        freqtrade_agent.py
        openbb_wrapper.py
        qlib_adapter.py
        trading_core.py
    trainer/
        self_trainer.py
        trainer_trigger.py
    updater/
        __init__.py
        auto_updater.py
    utils/
        config_loader.py
        environment.py
        logger.py
        telemetry.py
    vision/
        __init__.py
        capture.py
        image_vision.py
        ip_webcam_vision.py
        object_vision.py
        ocr_module.py
        ocr_reader.py
        voice_trigger.py
        yolo_handler.py
    voice/
        README.md
        __init__.py
        coqui_tts.py
        elevenlabs_tts.py
        nari_tts.py
        stt.py
        tts.py
        voice_bridge.py
        voice_identity.py
        vosk_stt.py
        whisper_engine.py
        whisper_stt.py
        yolov8_engine.py
        engine/
            coqui_tts.py
            elevenlabs_tts.py
            whisper_stt.py

FILE PREVIEW

## CHANGELOG.md

### Ciclo 019
- Creato `hierarchy_controller.py` per definizione core-controller e comunicazioni interne tra agenti

### Ciclo 020
- Creato `strategic_coordinator.py` con mappatura obiettivi, log interazioni e scelta agenti

### Ciclo 021
- Creato modulo `cognitive_simulator.py` per apprendimento esperienziale e adattamento comportamentale

## README.md
# AION ‚Äì Advanced Intelligence Of Nexus

üî¨ **AION** √® un sistema AI evolutivo full-stack, autonomo, multimodale e cognitivamente attivo.
Progettato per **apprendere**, **riflettere**, **generare codice** e **interagire** con ambienti complessi in tempo reale.

## üß† Caratteristiche Principali

- üß† **Autonomia cognitiva** ‚Äì Apprende da esperienze passate, simula riflessioni e ottimizza strategie.
- üó∫Ô∏è **Pianificazione intelligente** ‚Äì Crea piani operativi e migliora tramite feedback (AZR).
- üé§ **Multimodalit√† attiva** ‚Äì Supporta voce, testo, immagini e input sensoriali reali.
- üõ†Ô∏è **Autogenerazione codice** ‚Äì Scrive e modifica moduli Python in autonomia.
- üìä **Supervisione interna** ‚Äì Telemetria cognitiva, metriche performance e logging avanzato.
- üß© **Architettura modulare** ‚Äì Ogni componente √® plug&play e indipendente.

---

## üìÇ Struttura del Progetto

```plaintext
‚îú‚îÄ‚îÄ main.py                    # Entry point principale
‚îú‚îÄ‚îÄ start_fullmode.py         # Avvio completo in modalit√† "Jarvis+"
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ Neo/                  # Agenti evolutivi, ragionamento e simulazione
‚îÇ   ‚îú‚îÄ‚îÄ GPT/                  # Prompting e generazione LLM
‚îÇ   ‚îú‚îÄ‚îÄ AZR/                  # Modulo Reasoning e feedback
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/            # Interfaccia utente (Tk + Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ Reasoner/             # Catene logiche e planning
‚îú‚îÄ‚îÄ tools/                    # Logger, loader, scheduler, tester
‚îú‚îÄ‚îÄ config/                   # Configurazioni e ambienti
‚îú‚îÄ‚îÄ culture/                  # File cognitivi e conoscenza appresa
‚îî‚îÄ‚îÄ memory/                   # Memoria esperienziale degli agenti

## üöÄ Modalit√† GENESIS
Per avviare Mercurius‚àû con tutti i moduli attivi, eseguire:

```bash
python scripts/aion_boot.py
```

Il comando abilita la rete di agenti (OpenAI, Ollama, AZR), la voce (Whisper + gTTS) e la visione YOLO tramite webcam IP.

## üõ∞ Mission Controller Evolutivo
Il file `orchestrator/mission_controller.py` introduce un controller che gestisce un ciclo di self-questioning tra gli agenti (Reasoner, AZR e Codex). Ogni workspace contiene un prompt dedicato e il controller salva log e patch generate in automatico.

Per una prova rapida √® disponibile la GUI Streamlit:

```bash
streamlit run modules/dashboard/mission_gui.py
```

Da qui √® possibile creare nuovi workspace, avviare il ciclo evolutivo e visualizzare i log della sandbox.

## üõ† Generazione automatica del prompt per GPT-Engineer

Sono disponibili due script per creare i file di lavoro:

1. `scripts/update_project_tree.py` aggiorna `project_tree.txt` con l'albero del repository e le prime 100 righe dei file di testo.
2. `scripts/build_prompt.py` unisce `project_tree.txt` e `prompt_commands.txt` nel file finale `prompt.txt`.

### Utilizzo manuale

```bash
python scripts/update_project_tree.py
python scripts/build_prompt.py
```

### Integrazione con Git

Per aggiornare automaticamente `project_tree.txt` ad ogni `git pull` o merge:

```bash
# abilita i githook personalizzati
git config core.hooksPath githooks
```

I file `githooks/post-merge` (Linux/macOS) e `githooks/post-merge.bat` (Windows)
invocano lo script di aggiornamento dopo ogni merge.

In alternativa lo script pu√≤ essere pianificato con `cron` o "Operazioni pianificate" su Windows.


## ai_launcher.py
import subprocess
import requests
import time
import os
from typing import List

from utils.logger import get_file_logger

LOG_FILE = os.path.join("logs", "service_launcher.log")
logger = get_file_logger("ServiceLauncher", LOG_FILE)

def is_service_running(url: str, timeout: int = 2) -> bool:
    """Check if a service responds on the given URL."""
    try:
        response = requests.get(url, timeout=timeout)
        return response.status_code in [200, 401, 403]
    except requests.exceptions.RequestException:
        return False

def launch_service(name: str, url: str, command: List[str], delay: int = 5, retries: int = 5) -> None:
    """Ensure that a service is running, otherwise try to start it."""
    if is_service_running(url):
        logger.info(f"{name} √® gi√† attivo su {url}")
        return

    logger.info(f"Avvio {name}: {' '.join(command)}")
    subprocess.Popen(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    for _ in range(retries):
        if is_service_running(url):
            logger.info(f"{name} avviato correttamente.")
            return
        time.sleep(delay)

    logger.error(f"{name} non risponde su {url}")

def ensure_ai_online():
    launch_service("Ollama", "http://localhost:11434", ["ollama", "serve"], delay=3)
    launch_service("Ollama3", "http://localhost:11434/api/tags", ["ollama", "run", "llama3"], delay=3)
    launch_service("AZR", "http://localhost:4010/introspect", ["python", "agents/azr_server.py"], delay=2)
    launch_service("JOSCH", "http://localhost:3020/ping", ["python", "integrations/bridge_josch.py"], delay=2)
    launch_service("n8n", "http://localhost:5678", ["n8n", "start"], delay=4)

if __name__ == "__main__":
    ensure_ai_online()

## dashboard.py
# dashboard.py
"""
Mercurius‚àû GUI ‚Äì Interfaccia interattiva con stream webcam, trascrizione vocale, stato agenti
"""

import sys
import cv2
import threading
import speech_recognition as sr
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QLabel, QPushButton,
    QTextEdit, QListWidget, QHBoxLayout, QSplitter, QGraphicsView, QGraphicsScene
)
from PyQt5.QtCore import Qt, QTimer, QThread, pyqtSignal
from PyQt5.QtGui import QImage, QPixmap


class WebcamThread(QThread):
    frame_ready = pyqtSignal(QImage)

    def run(self):
        cap = cv2.VideoCapture(0)
        while True:
            ret, frame = cap.read()
            if ret:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb.shape
                img = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
                self.frame_ready.emit(img)


class SpeechThread(QThread):
    result_ready = pyqtSignal(str)

    def run(self):
        recognizer = sr.Recognizer()
        mic = sr.Microphone()
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            while True:
                audio = recognizer.listen(source)
                try:
                    text = recognizer.recognize_google(audio, language="it-IT")
                    self.result_ready.emit(text)
                except sr.UnknownValueError:
                    self.result_ready.emit("[...]")
                except sr.RequestError:
                    self.result_ready.emit("‚ùå Errore STT")


class MercuriusDashboard(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("üß† Mercurius‚àû ‚Äì Interfaccia Sensoriale")
        self.setGeometry(100, 100, 1040, 640)

        self.menu = QListWidget()
        self.menu.addItems(["Stato", "Agenti", "Memoria", "Voce", "Visione", "Log", "Test"])
        self.menu.currentRowChanged.connect(self.change_section)

        self.content_area = QTextEdit()
        self.content_area.setReadOnly(True)

        self.btn_action = QPushButton("Esegui Comando")
        self.btn_action.clicked.connect(self.execute_action)

        sidebar = QVBoxLayout()
        sidebar.addWidget(QLabel("üîß Menu"))
        sidebar.addWidget(self.menu)
        sidebar.addWidget(self.btn_action)

        sidebar_widget = QWidget()
        sidebar_widget.setLayout(sidebar)

        self.splitter = QSplitter(Qt.Horizontal)
        self.splitter.addWidget(sidebar_widget)
        self.splitter.addWidget(self.content_area)

        layout = QHBoxLayout()
        layout.addWidget(self.splitter)
        self.setLayout(layout)

        self.timer = QTimer()
        self.timer.timeout.connect(self.refresh_status)
        self.timer.start(3000)

        # Webcam e STT
        self.cam_view = QLabel()
        self.scene = QGraphicsScene()
        self.stt_live = QTextEdit()
        self.stt_live.setReadOnly(True)

        self.cam_thread = WebcamThread()
        self.cam_thread.frame_ready.connect(self.update_cam)
        self.cam_thread.start()

        self.stt_thread = SpeechThread()
        self.stt_thread.result_ready.connect(self.update_speech)
        self.stt_thread.start()

[TRONCATO]

## dashboard_streamlit.py
import streamlit as st
st.title("Mercurius‚àû Dashboard")

## docker-compose.override.yml
# docker-compose.override.yml
version: "3.9"

services:
  mercurius:
    environment:
      - MERCURIUS_READY=true

  healthcheck:
    build: .
    command: ["python", "monitoring/health_check.py"]
    ports:
      - "8081:8080"
    depends_on:
      - mercurius

  metrics:
    build: .
    command: ["python", "monitoring/metrics_exporter.py"]
    ports:
      - "9100:9100"
    depends_on:
      - mercurius

  audit_dashboard:
    build: .
    command: ["streamlit", "run", "monitoring/log_dashboard.py", "--server.port", "8501"]
    ports:
      - "8501:8501"
    volumes:
      - ./logs:/app/logs
    depends_on:
      - mercurius

## docker-compose.yml

# docker-compose.yml
version: "3.9"

services:
  mercurius:
    build: .
    container_name: mercurius_ai
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./memory/long_term_data:/app/memory/long_term_data
      - ./logs:/app/logs
    ports:
      - "8088:8080"

## file_albero_locale.txt
./
  .env
  .gitignore
  CHANGELOG.md
  dashboard.py
  dashboard_streamlit.py
  file_albero_locale.txt
  list_files.py
  main.py
  pyproject.toml
  README.md
  requirements.txt
  seleziona_cartella.py
  setup.py
  start_fullmode.py
  .git/
    COMMIT_EDITMSG
    config
    description
    HEAD
    index
    ORIG_HEAD
    packed-refs
    filter-repo/
      already_ran
      changed-refs
      commit-map
      first-changed-commits
      ref-map
      suboptimal-issues
    hooks/
      applypatch-msg.sample
      commit-msg.sample
      fsmonitor-watchman.sample
      post-update.sample
      pre-applypatch.sample
      pre-commit.sample
      pre-merge-commit.sample
      pre-push.sample
      pre-rebase.sample
      pre-receive.sample
      prepare-commit-msg.sample
      push-to-checkout.sample
      sendemail-validate.sample
      update.sample
    info/
      exclude
      refs
    logs/
      HEAD
      refs/
        heads/
          main
        remotes/
          origin/
            main
    objects/
      00/
        0c4644329642ba78e2cd1ada115ebe379e4af6
        40e74021c0f90d510ff5aa9f38bf82908244ff
      01/
        b3671f539a7617178cbdd179a4a535602776f9
      02/
        c930a34428141958379765db4bb989840a88a3
      03/
        e6bb6588fb106c53a10dee28bf3bdb27ed2fc1
      0d/
        6a08a82018bce35f3ab880ed1fa1df80cffbf4
      0f/
        50667778bb680abbcad2348d51c2c02a0078c3
      12/
        530a8fb7fc2b755796dfab2086c44b8df7a246
      14/
        d8c1a972d89bd64097a3559dfb766305f5f0f2
        d94ebe296e560f13495faaeb9648bd243ef208
      19/
        8a47d2914853cb4f213bbd8b73a3e26fe16cad
      1d/
        4ba5c319325d9e9d189299deb4901629f3f395
      20/
        056a4c1fd358f0d139b65c43fb63b518cd3848
      21/
        9d837349412896a75ceb68aab0b38dab13ed97
      24/
        a5784c4fc7c271693ed05e4f46aa863d7e5f6e
      2b/
        77c9c83c394c02fd5d95e687efb73468940a3a
      2d/
        ebc1262e7a92680d539c8f002591e9ab77593a
      2e/
        ef76e34370364369b94979cdc99527b20617f3
      2f/
        28bc65fdf6e148b20c5f0738f09285640cfc6f
        c19b97dd57ea97cfd10600ac68b4d61747c996
      31/
        84ce130d0f13fa15de77c28ac2486eb1e28912
      32/
        1666aff24ebbb930479bcdacff81b954e43b21
        af33f12fb23d2c3ae21d49583b1d52c0bbafb6
      36/
[TRONCATO]

## goals.txt
Genera uno script Python che stampa 'Hello Strategic Brain'

## list_files.py
import os

with open("file_albero_locale.txt", "w", encoding="utf-8") as f:
    for root, dirs, files in os.walk("."):
        level = root.replace(os.getcwd(), '').count(os.sep)
        indent = '  ' * level
        f.write(f"{indent}{os.path.basename(root)}/\n")
        subindent = '  ' * (level + 1)
        for file in files:
            f.write(f"{subindent}{file}\n")

## main.py
"""
main.py
========
Punto di ingresso principale per l'esecuzione del sistema Mercurius‚àû.

Funzionalit√†:
- Caricamento ambiente e configurazioni
- Inizializzazione pipeline: dati, features, modello
- Esecuzione strategia di trading adattiva
- Simulazione esperienza cognitiva (AI Evolutiva)
"""

import logging
from utils.logger import setup_logger
from utils.config_loader import load_config
from utils.environment import Environment
from data.market_data_handler import MarketDataHandler
from data.feature_engineering import FeatureEngineer
from models.model_trainer import ModelTrainer
from strategies.strategy_executor import StrategyExecutor
from agents.adaptive_trader import AdaptiveTrader
from agents.memory_manager import MemoryManager
from orchestrator.autonomy_controller import AutonomyController


def load_env():
    """Carica variabili d‚Äôambiente e mostra lo stato di Mercurius‚àû."""
    env = Environment()
    print("üîê Ambiente Mercurius‚àû caricato:")
    print(" - OpenAI Model:", env.get("OPENAI_CHAT_MODEL"))
    print(" - WM_USER:", env.get("WM_USER"))
    print(" - MCP_URL:", env.get("MCP_INTROSPECT_URL"))
    return env


def initialize_system():
    """Inizializza il sistema con tutte le componenti core."""
    config = load_config("config.yaml")
    logger = setup_logger(name="MercuriusMain")

    logger.info("üì¶ Caricamento configurazione completato.")
    logger.debug(f"Configurazione caricata: {config}")

    memory = MemoryManager(config)
    data_handler = MarketDataHandler(config)
    feature_engineer = FeatureEngineer(config)
    model_trainer = ModelTrainer(config)
    strategy = StrategyExecutor(config)
    agent = AdaptiveTrader(config, memory, model_trainer, strategy)

    logger.info("üîß Sistema inizializzato correttamente.")
    return {
        "config": config,
        "logger": logger,
        "memory": memory,
        "data_handler": data_handler,
        "feature_engineer": feature_engineer,
        "model_trainer": model_trainer,
        "strategy": strategy,
        "agent": agent
    }


def run_pipeline(components: dict):
    """Esegue il ciclo completo di analisi, apprendimento e trading."""
    logger = components["logger"]
    data_handler = components["data_handler"]
    feature_engineer = components["feature_engineer"]
    model_trainer = components["model_trainer"]
    strategy = components["strategy"]
    agent = components["agent"]

    logger.info("üöÄ Avvio pipeline operativa Mercurius‚àû...")

    raw_data = data_handler.fetch_market_data()
    logger.info(f"üìä Dati di mercato ricevuti: {len(raw_data)} records")

    features = feature_engineer.transform(raw_data)
    logger.info("üß† Feature engineering completato.")

    model = model_trainer.train(features)
    logger.info("ü§ñ Modello addestrato con successo.")

    signals = strategy.generate_signals(model, features)
    logger.info(f"üìà Segnali generati: {len(signals)}")

    agent.execute_trades(signals)
    logger.info("‚úÖ Trade eseguiti con successo.")


def simulate_experience():
    """Simula esperienze per il controller cognitivo autonomo."""
    print("\nüß† Avvio simulazione esperienze cognitive...\n")
    auto = AutonomyController()

    experiences = [
        {"action": "Avvia scansione", "outcome": "Area rilevata", "success": True, "context": {}},
        {"action": "Connessione API", "outcome": "Errore 500", "success": False, "context": {"error": "Internal Server Error"}},
        {"action": "Naviga percorso", "outcome": "Riuscito", "success": True, "context": {"speed": "3.2m/s"}},
    ]
[TRONCATO]

## package-lock.json
{
  "name": "mercurius_infinite_final",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "dependencies": {
        "@types/react": "^19.1.6",
        "react": "^19.1.0"
      }
    },
    "node_modules/@types/react": {
      "version": "19.1.6",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-19.1.6.tgz",
      "integrity": "sha512-JeG0rEWak0N6Itr6QUx+X60uQmN+5t3j9r/OVDtWzFXKaj6kD1BwJzOksD0FF6iWxZlbE1kB0q9vtnU2ekqa1Q==",
      "license": "MIT",
      "dependencies": {
        "csstype": "^3.0.2"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "19.1.0",
      "resolved": "https://registry.npmjs.org/react/-/react-19.1.0.tgz",
      "integrity": "sha512-FS+XFBNvn3GTAWq26joslQgWNoFu08F4kl0J4CgdNKADkdSGXQyTCnKteIAJy96Br6YbpEU1LSzV5dYtjMkMDg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    }
  }
}

## package.json
{
  "dependencies": {
    "@types/react": "^19.1.6",
    "react": "^19.1.0"
  }
}

## print_tree.py
import os

def print_tree(startpath, file=None):
    for root, dirs, files in os.walk(startpath):
        level = root.replace(startpath, '').count(os.sep)
        indent = ' ' * 4 * level
        line = f"{indent}üìÅ {os.path.basename(root)}"
        print(line) if file is None else print(line, file=file)
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            fline = f"{subindent}- {f}"
            print(fline) if file is None else print(fline, file=file)

if __name__ == "__main__":
    with open("mercurius_tree.txt", "w", encoding="utf-8") as out_file:
        print("üìÇ Mercurius‚àû Project Structure", file=out_file)
        print("=" * 40, file=out_file)
        print_tree(".", file=out_file)

## prompt_commands.txt
# Aggiungi qui le istruzioni operative per GPT-Engineer

## pyproject.toml
[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

## pytest.ini
[pytest]
addopts = -q
testpaths = tests
norecursedirs =
    AutoGPT
    */forge

## requirements.txt
absl-py==2.3.0
aiofiles==24.1.0
altair==5.5.0
altgraph==0.17.4
annotated-types==0.7.0
anyio==4.9.0
argbind==0.3.9
asttokens==3.0.0
attrs==25.3.0
audioread==3.0.1
bcrypt==4.3.0
beautifulsoup4==4.13.4
blinker==1.9.0
cachetools==5.5.2
certifi==2025.4.26
cffi==1.17.1
chardet==5.2.0
charset-normalizer==3.4.2
click==8.2.1
colorama==0.4.6
comtypes==1.4.11
contourpy==1.3.2
cryptography==45.0.3
cssselect==1.3.0
cycler==0.12.1
decorator==5.2.1
defusedxml==0.7.1
descript-audio-codec==1.0.0
descript-audiotools==0.7.2
diskcache==5.6.3
distro==1.9.0
docstring_parser==0.16
einops==0.8.1
executing==2.2.0