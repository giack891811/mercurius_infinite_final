Questa è la parte 19 di project_tree. Continua da quella precedente.

## start_fullmode.py
def main():
    print("🔁 Avvio completo Mercurius∞")
    print("🧠 Modalità Jarvis+ attiva: Visione, Voce, Dashboard, AI Cognitiva")
    # Avviare sequenze di bootstrap dei moduli AI
    from modules.Neo.trainer_orchestrator import bootstrap_agents
    bootstrap_agents()

if __name__ == "__main__":
    main()

## start_voice_interface.py
"""
Script: start_voice_interface
Funzione: Comunicazione vocale Mercurius∞ da file audio nella root.
Autore: Mercurius∞ AI Engineer
"""

import os
from modules.voice_bridge.multimodal_controller import MultimodalController
from modules.ai_kernel.agent_core import AgentCore

AUDIO_FILE = "audio_input.wav"  # Assicurati che il file sia nella root!

def ensure_audio_exists(path):
    if not os.path.exists(path):
        print(f"[ERRORE] File audio non trovato: {path}")
        exit(1)

def avvia_interazione_vocale(audio_file):
    ensure_audio_exists(audio_file)

    agente = AgentCore()
    multimodale = MultimodalController()

    print("🎙️ Avvio comunicazione vocale...")
    multimodale.listen_and_respond(audio_file, agente.process_input)

if __name__ == "__main__":
    avvia_interazione_vocale(AUDIO_FILE)

## task_manager_cli.py
from modules.task_manager_cli import main

if __name__ == "__main__":
    main()

## test_exp.json
[
  {
    "tags": [
      "unit"
    ],
    "result": "ok",
    "timestamp": "2025-06-01T12:23:47.154527"
  }
]

## .github/workflows/mercurius_ci.yml
# .github/workflows/ci.yml
name: Mercurius CI/CD

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: ⬇️ Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest flake8

      - name: 🔍 Lint check (flake8)
        run: |
          flake8 . --exclude=.venv

      - name: ✅ Run unit & integration tests
        run: |
          pytest tests/ > test_results.txt
        continue-on-error: true

      - name: 📤 Upload test artifacts
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: test_results.txt

      - name: 🐳 Build Docker image
        run: docker build -t mercurius:ci .

  deploy-staging:
    needs: build-and-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: ⬇️ Checkout repository
        uses: actions/checkout@v4

      - name: 🚀 Simulated deploy to staging
        run: echo "🚀 Deploying to staging... [Simulazione]"

  refresh-mcp:
    needs: deploy-staging
    runs-on: ubuntu-latest
    steps:
      - name: 🔄 Refresh MCP introspection
        run: echo "🔄 MCP Introspection Updated"

  generate-colab-notebook:
    needs: refresh-mcp
    runs-on: ubuntu-latest
    steps:
      - name: 📘 Generate Colab Notebook
        run: echo "📘 Colab notebook generation simulated"

  notify-slack:
    needs: generate-colab-notebook
    runs-on: ubuntu-latest
    steps:
      - name: 📩 Slack notification
        run: echo "📩 Slack message simulation"

  mercurius-autonomous-plan:
    needs: notify-slack
    runs-on: ubuntu-latest
    steps:
      - name: 🧠 Run Mercurius Autonomous Action Plan
        run: echo "🧠 Executing Mercurius Autonomous Plan..."

## agents/__init__.py
"""
📦 agents/__init__.py
Modulo inizializzatore per il caricamento dinamico degli agenti AI della rete neurale Mercurius∞
"""

# Placeholder: gli agenti verranno creati come moduli singoli in agents/
# Ogni modulo dovrà contenere una classe con lo stesso nome dell'agente definito in genesis_config.yaml
# Esempio: agents/ChatGPT4.py -> class ChatGPT4:

## agents/adaptive_trader.py
# agents/adaptive_trader.py
"""
adaptive_trader.py
==================
Agente autonomo per esecuzione dinamica di operazioni di trading sulla base
dei segnali ricevuti, stato di memoria, e adattamento esperienziale (AZR).
"""
from modules.experience.azr_analyzer import AZRAnalyzer
from modules.experience.experience_memory import ExperienceMemory

class AdaptiveTrader:
    def __init__(self, config, memory_manager, model_trainer, strategy_executor):
        self.config = config
        self.memory = memory_manager
        self.model_trainer = model_trainer
        self.strategy = strategy_executor
        self.trade_log = []
        self.experience_memory = ExperienceMemory(config)
        self.azr = AZRAnalyzer(self.experience_memory, config)

    def evaluate_signals(self, signals):
        """Valuta i segnali di trading ricevuti in base al contesto corrente."""
        evaluated = []
        for signal in signals:
            confidence = signal.get('confidence', 0.5)
            if confidence > self.config.get("min_confidence", 0.6):
                evaluated.append(signal)
        return evaluated

    def execute_trades(self, signals):
        """Esegue le operazioni basandosi sui segnali validati."""
        valid_signals = self.evaluate_signals(signals)
        for signal in valid_signals:
            trade = {
                "symbol": signal["symbol"],
                "action": signal["action"],
                "quantity": self._calculate_quantity(signal),
                "timestamp": signal.get("timestamp")
            }
            # Simula risultato dell'operazione di trading
            result = self._simulate_trade_result(trade)
            feedback = self._generate_feedback(trade, result)
            # Registra l'esperienza e aggiorna memoria
            self.experience_memory.record_experience(signal, trade, result, feedback)
            self.memory.record_trade(trade)
            self.trade_log.append(trade)
            print(f"Eseguito trade: {trade} → Profit: {result['profit']:.2f}")
        # Dopo aver eseguito i trade, applica eventuali adattamenti (AZR)
        self._adaptive_adjustment()

    def _calculate_quantity(self, signal):
        """Calcola la quantità da tradare in base al rischio e asset allocation."""
        base_qty = self.config.get("base_trade_qty", 100)
        volatility_factor = signal.get("volatility", 1)
        return int(base_qty / volatility_factor)

    def _simulate_trade_result(self, trade):
        """Mock del risultato di un'operazione (calcolo profitto casuale)."""
        import random
        direction = 1 if trade["action"].upper() == "BUY" else -1
        price_diff = random.uniform(-5, 10) * direction
        return {"profit": round(price_diff * trade["quantity"] * 0.01, 2)}

    def _generate_feedback(self, trade, result):
        """Mock di feedback evolutivo basato sul risultato dell'operazione."""
        return {
            "profit_margin": result["profit"] / (trade["quantity"] + 1),
            "risk_level": trade["quantity"]
        }

    def _adaptive_adjustment(self):
        """Applica AZR per modificare i parametri in base all’esperienza recente."""
        result = self.azr.apply_adaptation()
        # L'adattamento AZR modifica la config in place; notifica eventuali cambiamenti rilevanti
        if result and result.get("decision", {}).get("action") == "decrease_risk":
            new_qty = result["decision"]["new_qty"]
            print(f"🔄 Adattamento AZR: ridotta base_trade_qty a {new_qty}")

    def get_trade_history(self):
        """Restituisce lo storico delle operazioni eseguite."""
        return self.trade_log

## agents/agent_comm.py
# agents/agent_comm.py

"""
Modulo: agent_comm.py
Descrizione: Gestione della comunicazione tra agenti all'interno della rete Mercurius∞.
Permette lo scambio di messaggi strutturati tra agenti identificati da ID.
"""

from typing import Dict, List
from datetime import datetime

# Simulazione struttura di memorizzazione dei messaggi
MESSAGES: Dict[str, List[Dict]] = {}


def send_message(sender_id: str, receiver_id: str, content: str) -> None:
    """
    Invia un messaggio da un agente a un altro.
    """
    message = {
        "timestamp": datetime.now().isoformat(),
        "from": sender_id,
        "to": receiver_id,
        "content": content
    }
    if receiver_id not in MESSAGES:
        MESSAGES[receiver_id] = []
    MESSAGES[receiver_id].append(message)


def get_messages(agent_id: str) -> List[Dict]:
    """
    Recupera tutti i messaggi ricevuti da un agente.
    """
    return MESSAGES.get(agent_id, [])

## agents/agent_generator.py
# agents/agent_generator.py

"""
Modulo: agent_generator.py
Descrizione: Generazione dinamica di nuovi agenti per Mercurius∞ con personalità e missione specifiche.
"""

from typing import Dict
import uuid


class Agent:
    def __init__(self, name: str, personality: str, mission: str):
        self.id = str(uuid.uuid4())
        self.name = name
        self.personality = personality
        self.mission = mission

    def describe(self) -> Dict:
        return {
            "id": self.id,
            "name": self.name,
            "personality": self.personality,
            "mission": self.mission
        }


def generate_agent(personality: str, mission: str, name: str = "Unnamed Agent") -> Agent:
    """
    Crea un nuovo agente con parametri definiti.
    """
    return Agent(name, personality, mission)

## agents/azr.py
"""AZR reasoning agent."""
from modules.llm.azr_reasoner import AZRAgent

class AZR:
    def __init__(self):
        self.agent = AZRAgent()

    def analyze(self, text: str) -> str:
        return self.agent.analyze(text)

    def neural_feedback(self):
        print("[AZR] feedback cycle active")

## agents/azr_server.py
"""azr_server.py
Modulo FastAPI che espone l'endpoint introspect per il Reasoner AZR.
Utilizzabile da Mercurius∞ per sapere se AZR è attivo.
"""

from fastapi import FastAPI
import uvicorn

app = FastAPI(title="AZR Server")

@app.get("/introspect")
def introspect():
    return {"status": "AZR is running", "version": "1.0", "agent": "AZR"}

def start_server(host: str = "0.0.0.0", port: int = 4010):
    uvicorn.run("agents.azr_server:app", host=host, port=port, reload=True)

if __name__ == "__main__":
    start_server()

## agents/memory_manager.py
"""
memory_manager.py
=================
Gestione della memoria storica delle operazioni, segnali e parametri per l'adattività dell'agente.
"""

class MemoryManager:
    def __init__(self, config):
        self.config = config
        self.trade_memory = []
        self.signal_memory = []
        self.context = {}

    def record_trade(self, trade):
        """Registra un trade eseguito nella memoria storica."""
        self.trade_memory.append(trade)
        self._update_context(trade)

    def record_signal(self, signal):
        """Registra un segnale ricevuto."""
        self.signal_memory.append(signal)

    def _update_context(self, trade):
        """Aggiorna il contesto operativo in base ai trade recenti."""
        symbol = trade["symbol"]
        self.context[symbol] = self.context.get(symbol, 0) + 1

    def get_recent_trades(self, limit=10):
        """Restituisce gli ultimi trade effettuati."""
        return self.trade_memory[-limit:]

    def get_signal_history(self, symbol=None):
        """Restituisce la memoria dei segnali per uno specifico simbolo o tutti."""
        if symbol:
            return [s for s in self.signal_memory if s["symbol"] == symbol]
        return self.signal_memory

    def clear(self):
        """Resetta la memoria."""
        self.trade_memory.clear()
        self.signal_memory.clear()
        self.context.clear()

    def export_summary(self):
        """Ritorna una sintesi dello stato attuale della memoria."""
        return {
            "tot_trades": len(self.trade_memory),
            "tot_signals": len(self.signal_memory),
            "context_symbols": list(self.context.keys())
        }

    def analyze_bias(self):
        """Analizza possibili bias nel comportamento di trading."""
        counts = {}
        for trade in self.trade_memory:
            symbol = trade["symbol"]
            counts[symbol] = counts.get(symbol, 0) + 1
        return sorted(counts.items(), key=lambda x: -x[1])

## agents/ollama.py
"""Ollama local LLM agent."""
import requests
import json

class OLLAMA:
    def __init__(self, url: str = "http://localhost:11434/api/generate", model: str = "llama3"):
        self.url = url
        self.model = model

    def chat(self, prompt: str) -> str:
        data = {"model": self.model, "prompt": prompt}
        try:
            r = requests.post(self.url, headers={"Content-Type": "application/json"}, data=json.dumps(data))
            r.raise_for_status()
            return r.json().get("response", "").strip()
        except Exception as e:
            return f"[Ollama error] {e}"

    def ask(self, prompt: str) -> str:
        return self.chat(prompt)

    def neural_feedback(self):
        print("[Ollama] feedback cycle active")

## agents/openai.py
"""OpenAI agent wrapper for Mercurius∞."""
import os
import openai

class OPENAI:
    def __init__(self, model: str = "gpt-3.5-turbo"):
        self.model = model
        openai.api_key = os.getenv("OPENAI_API_KEY", "")

    def chat(self, prompt: str) -> str:
        try:
            resp = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=200,
            )
            return resp["choices"][0]["message"]["content"].strip()
        except Exception as e:
            return f"[OpenAI error] {e}"

    def neural_feedback(self):
        print("[OpenAI] feedback cycle active")

## agents/azr/azr_supervisor.py
"""
azr_supervisor.py
=================
Controllore strategico per adattamento Mercurius∞ basato su esperienze.
"""

from modules.experience.azr_analyzer import AZRAnalyzer
from modules.metrics.performance_metrics import PerformanceMetrics


class AZRSupervisor:
    def __init__(self, agent, experience_memory, config):
        self.agent = agent
        self.memory = experience_memory
        self.config = config
        self.analyzer = AZRAnalyzer(self.memory, config)

    def supervise(self):
        analysis = self.analyzer.analyze_recent_performance()
        suggestion = analysis.get("decision", {})
        if suggestion.get("action") == "decrease_risk":
            new_qty = suggestion["new_qty"]
            self.agent.adjust_strategy({"base_trade_qty": new_qty})
        return analysis

## analytics/__init__.py

## analytics/behavior_logger.py
# analytics/behavior_logger.py
"""
Modulo: behavior_logger.py
Descrizione: Log comportamentale centralizzato per Mercurius∞.
Registra errori, fallback, performance-hit e successi in un file JSONL con TTL.
"""

from pathlib import Path
from datetime import datetime
import json
import hashlib

LOG_FILE = Path("logs/behavior_log.jsonl")
LOG_FILE.parent.mkdir(parents=True, exist_ok=True)


class BehaviorLogger:
    def __init__(self):
        self.file = LOG_FILE

    def log(self, event: str, details: dict):
        entry = {
            "ts": datetime.utcnow().isoformat(),
            "event": event,
            "hash": hashlib.md5(event.encode()).hexdigest()[:6],
            "details": details,
        }
        with self.file.open("a", encoding="utf-8") as f:
            f.write(json.dumps(entry) + "\n")

    def tail(self, n: int = 100):
        if not self.file.exists():
            return []
        return self.file.read_text(encoding="utf-8").splitlines()[-n:]

## analytics/meta_learner.py
# analytics/meta_learner.py
"""
Modulo: meta_learner.py
Descrizione: Analizza il Behavior Log e calcola KPI sulle performance
per suggerire miglioramenti a moduli/parametri.
"""

from collections import Counter
from typing import Dict, Any, List
import json

from analytics.behavior_logger import BehaviorLogger

class MetaLearner:
    def __init__(self):
        self.logger = BehaviorLogger()

    def _load_events(self) -> List[Dict[str, Any]]:
        raw = self.logger.tail(5000)
        return [json.loads(line) for line in raw]

    def kpi(self) -> Dict[str, Any]:
        data = self._load_events()
        total = len(data)
        errors = [e for e in data if e["event"] == "error"]
        successes = [e for e in data if e["event"] == "success"]
        modules = Counter(e["details"].get("module", "unknown") for e in errors)
        return {
            "total_events": total,
            "error_rate": len(errors) / total if total else 0,
            "success_rate": len(successes) / total if total else 0,
            "top_error_modules": modules.most_common(5),
        }

    def recommend(self) -> str:
        kpi = self.kpi()
        if kpi["error_rate"] > 0.2:
            worst = kpi["top_error_modules"][0][0] if kpi["top_error_modules"] else "unknown"
            return f"🤖 Consiglio: test approfonditi su modulo '{worst}' (errore>20%)."
        return "✅ Sistema stabile: nessuna azione critica."

## analytics/neuro_optimizer.py
# analytics/neuro_optimizer.py
"""
Modulo: neuro_optimizer.py
Descrizione: Usa MetaLearner + LLM per proporre refactor automatici ai moduli peggiori.
"""

import os
import openai
from pathlib import Path

from analytics.meta_learner import MetaLearner

class NeuroOptimizer:
    def __init__(self, model="gpt-3.5-turbo"):
        self.meta = MetaLearner()
        self.model = model
        openai.api_key = os.getenv("OPENAI_API_KEY")

    def _call_llm(self, prompt: str) -> str:
        resp = openai.ChatCompletion.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800,
        )
        return resp["choices"][0]["message"]["content"]

    def suggest_patch(self) -> dict | None:
        rec = self.meta.recommend()
        if "test approfonditi su modulo" not in rec:
            return None
        module_name = rec.split("'")[1]
        file_path = Path(f"{module_name.replace('.', '/')}.py")
        if not file_path.exists():
            return None
        original_code = file_path.read_text(encoding="utf-8")
        prompt = (
            "Migliora il codice seguente correggendo bug, aggiungendo docstring "
            "e typing. Restituisci il file completo.\n\n"
            f"FILE: {file_path}\n```python\n{original_code}\n```"
        )
        new_code = self._call_llm(prompt)
        return {"path": str(file_path), "code": new_code}

## analytics/self_patch_engine.py
# analytics/self_patch_engine.py
"""
Modulo: self_patch_engine.py
Descrizione: Genera una patch git e crea automaticamente un branch+commit con i
suggerimenti di NeuroOptimizer.
"""

import subprocess
from pathlib import Path
from typing import Optional
from analytics.neuro_optimizer import NeuroOptimizer
from analytics.behavior_logger import BehaviorLogger

class SelfPatchEngine:
    def __init__(self, repo_root: str = "."):
        self.root = Path(repo_root)
        self.optimizer = NeuroOptimizer()
        self.logger = BehaviorLogger()

    def _git(self, *args):
        return subprocess.run(["git", *args], cwd=self.root, capture_output=True, text=True)

    def apply_patch(self) -> Optional[str]:
        suggestion = self.optimizer.suggest_patch()
        if not suggestion:
            print("Nessuna patch suggerita.")
            return None
        path = Path(suggestion["path"])
        branch = f"auto_patch_{path.stem}"
        self._git("checkout", "-B", branch)
        path.write_text(suggestion["code"], encoding="utf-8")
        self._git("add", str(path))
        self._git("commit", "-m", f"🤖 Auto-patch {path.name} (NeuroOptimizer)")
        self.logger.log("auto_patch", {"path": suggestion["path"]})
        print(f"✅ Patch applicata su branch {branch}")
        return branch

## cognition/__init__.py

## cognition/agent_router.py
# cognition/agent_router.py
"""
Modulo: agent_router.py
Descrizione: Seleziona l'agente ottimale per un task usando CognitiveMap + TaskMemory.
"""

import re
from typing import Dict

from cognition.cognitive_map import CognitiveMap
from cognition.task_memory import TaskMemory


class AgentRouter:
    def __init__(self, c_map: CognitiveMap, memory: TaskMemory):
        self.map = c_map
        self.memory = memory
        # pattern → lista agent_type preferiti
        self.rules: Dict[str, list[str]] = {
            r"\b(trade|buy|sell)\b": ["trading"],
            r"\b(voice|speak|listen)\b": ["voice"],
            r"\b(debug|validate|logic)\b": ["cognitive"],
        }

    def _match_rule(self, task: str):
        for pattern, types in self.rules.items():
            if re.search(pattern, task, re.IGNORECASE):
                return types
        return ["cognitive"]

    def choose_agent(self, task: str) -> str:
        desired_types = self._match_rule(task)
        candidates = []
        for t in desired_types:
            candidates.extend(self.map.agents_by_type(t))
        # se più candidati, usa memoria di successo
        if candidates:
            return self.memory.suggest_best(candidates)
        # fallback: primo agente generico
        return next(iter(self.map.nodes))

    def record_result(self, agent: str, task: str, success: bool):
        self.memory.add_record(agent, task, success)

## cognition/cognitive_map.py
# cognition/cognitive_map.py
"""
Modulo: cognitive_map.py
Descrizione: Rappresentazione dinamica della mappa mentale di Mercurius∞.
Ogni nodo è un agente, ogni arco è una dipendenza o canale di comunicazione.
"""

from collections import defaultdict
from typing import Dict, List


class CognitiveMap:
    def __init__(self):
        # {agent: {"type": "cognitive|trading|voice", "edges": [to_agent, ...]}}
        self.nodes: Dict[str, Dict] = defaultdict(lambda: {"type": "generic", "edges": []})

    # ---------- Gestione nodi ----------
    def add_agent(self, name: str, agent_type: str = "generic"):
        self.nodes[name]["type"] = agent_type

    def link(self, src: str, dest: str):
        if dest not in self.nodes[src]["edges"]:
            self.nodes[src]["edges"].append(dest)

    def remove_agent(self, name: str):
        self.nodes.pop(name, None)
        for n in self.nodes.values():
            if name in n["edges"]:
                n["edges"].remove(name)

    # ---------- Query ----------
    def agents_by_type(self, agent_type: str) -> List[str]:
        return [a for a, meta in self.nodes.items() if meta["type"] == agent_type]

    def connections_of(self, name: str) -> List[str]:
        return self.nodes[name]["edges"]

    def to_dict(self):
        return self.nodes

## cognition/task_memory.py
# cognition/task_memory.py
"""
Modulo: task_memory.py
Descrizione: Salvataggio outcome dei task per apprendere preferenze di routing.
"""

from collections import deque
from typing import Dict, Any, Deque, List


class TaskMemory:
    def __init__(self, maxlen: int = 2000):
        self.records: Deque[Dict[str, Any]] = deque(maxlen=maxlen)

    def add_record(self, agent: str, task: str, success: bool):
        self.records.append({"agent": agent, "task": task, "success": success})

    def agent_score(self, agent: str) -> float:
        """Percentuale di successi dell’agente."""
        entries = [r for r in self.records if r["agent"] == agent]
        if not entries:
            return 0.5
        ok = sum(1 for e in entries if e["success"])
        return ok / len(entries)

    def suggest_best(self, candidates: List[str]) -> str:
        """Ritorna l’agente col punteggio più alto tra i candidati."""
        return max(candidates, key=self.agent_score)

## communications/__init__.py

## communications/email_assistant.py
# communications/email_assistant.py
"""
Modulo: email_assistant.py
Descrizione: Lettura e invio email via IMAP/SMTP con conferma SafetyGuard.
"""

import os
import smtplib
import imaplib
import email
from email.mime.text import MIMEText
from safety.safety_guard import SafetyGuard

IMAP_HOST = os.getenv("EMAIL_IMAP")
SMTP_HOST = os.getenv("EMAIL_SMTP")
EMAIL_USER = os.getenv("EMAIL_USER")
EMAIL_PASS = os.getenv("EMAIL_PASS")

class EmailAssistant:
    def __init__(self):
        self.guard = SafetyGuard(interactive=True)

    def read_latest(self, n=5):
        with imaplib.IMAP4_SSL(IMAP_HOST) as imap:
            imap.login(EMAIL_USER, EMAIL_PASS)
            imap.select("INBOX")
            typ, data = imap.search(None, "ALL")
            ids = data[0].split()[-n:]
            messages = []
            for num in ids[::-1]:
                typ, msg_data = imap.fetch(num, "(RFC822)")
                msg = email.message_from_bytes(msg_data[0][1])
                messages.append({"from": msg["From"], "subject": msg["Subject"]})
            return messages

    def send_email(self, to_addr: str, subject: str, body: str):
        safe_body = self.guard.filter_text(body)
        if safe_body is None:
            return False
        msg = MIMEText(safe_body)
        msg["Subject"] = subject
        msg["From"] = EMAIL_USER
        msg["To"] = to_addr
        with smtplib.SMTP_SSL(SMTP_HOST) as smtp:
            smtp.login(EMAIL_USER, EMAIL_PASS)
            smtp.send_message(msg)
        return True

## config/config.yaml
agents:
  enabled: ["OPENAI", "OLLAMA", "AZR"]

communication:
  feedback_loop: true
  max_retries: 3
  retry_delay: 2
  update_cycle_seconds: 60  # <--- questa riga mancava!

mission_defaults:
  run_mode: dialogic-autonomous
  tasks:
    - "#SELF_MISSION"
    - "#RUN_SELF_CHECK"

paths:
  transcripts: "memory/transcripts/"
  logs: "logs/"

## config/config_schema.py
# config_schema.py
CONFIG_SCHEMA = {
    "symbols": {"type": "list", "schema": {"type": "string"}},
    "base_trade_qty": {"type": "integer", "min": 1},
    "min_confidence": {"type": "float", "min": 0, "max": 1},
    "retrain_threshold": {"type": "float", "min": 0, "max": 1},
    "azr_profit_floor": {"type": "float", "min": 0}
}

## config/config_validator.py
# config_validator.py
import yaml
from cerberus import Validator
from config.config_schema import CONFIG_SCHEMA

def load_and_validate_config(path="config/config.yaml"):
    with open(path) as f:
        config = yaml.safe_load(f)
    v = Validator(CONFIG_SCHEMA)
    if not v.validate(config):
        raise ValueError(v.errors)
    return config

## config/genesis_config.yaml
# ⚙️ Configurazione Centrale – GENESIS_MODE
# Questo file controlla l'attivazione e la connessione tra i moduli AI di Mercurius∞

genesis_mode:
  activation_command: "#GENESIS_MODE"
  voice_trigger: "Hey Mercurius, attiva GENESIS"
  orchestrator_module: "core.orchestrator"
  mission_module: "core.self_mission"

agents:
  cognitive_core:
    - ChatGPT4
    - AZR
    - Ollama3
    - GPT4o
  evolution_engine:
    - GPTEngineer
    - MetaGPT
    - AutoGPT
    - AI2UI
  trading_stack:
    - FinRL
    - FinGPT
    - Qlib
    - OpenBB
    - Freqtrade
  creative_organizers:
    - SuperAGI
    - MicrosoftAutogen
    - CrewAI
  hardware_integration:
    - LocalAI
    - LeonAI
    - n8n
    - HuggingFaceAgents
  voice_system:
    - NariDia
    - ElevenLabs
    - Whisper
    - Vosk

communication:
  agent_protocol: "neural-messaging"
  update_cycle_seconds: 10
  feedback_loop: true

# Abilita il thinking loop
thinking_enabled: true

## config/prod_settings.yaml
# config/prod_settings.yaml
---
logging_level: INFO
agents:
  cognitive:
    - ChatGPTAgent
    - Ollama3Agent
    - AZRAgent
    - GPT4oAgent
  trading:
    - AdaptiveTrader
  evolution:
    - MetaTeamAgent
communication:
  feedback_loop: true
  update_cycle_seconds: 30
sleep_threshold: 300

## config/self_profile.yaml
# config/self_profile.yaml
name: Mercurius∞
version: "1.0"
values:
  - curiosity
  - transparency
  - service