Questa è la parte 56 di project_tree. Continua da quella precedente.

        return f"[{self.name}] Addestramento RL su dataset: {dataset_path} in env: {environment}"

    def simulate(self, steps: int = 500) -> str:
        return f"[{self.name}] Simulazione completata per {steps} step RL"

    def deploy(self, model_name: str) -> str:
        return f"[{self.name}] Strategia RL deployata: {model_name}"

### --- trading/freqtrade_agent.py --- ###
class FreqtradeAgent:
    def __init__(self):
        self.name = "Freqtrade"

    def execute_task(self, strategy_name: str, action: str = "backtest") -> str:
        return f"[{self.name}] Strategia '{strategy_name}' eseguita in modalità {action}."

### --- trading/openbb_wrapper.py --- ###
class OpenBBWrapper:
    def __init__(self):
        self.name = "OpenBB"

    def execute_task(self, command: str, options: dict = {}) -> str:
        return f"[{self.name}] Comando OpenBB eseguito: {command}"

### --- trading/qlib_adapter.py --- ###
class QlibAdapter:
    def __init__(self):
        self.name = "Qlib"

    def execute_task(self, symbol: str, timeframe: str, mode: str = "forecast") -> str:
        return f"[{self.name}] {mode.upper()} per {symbol} su {timeframe} eseguita."

### --- trading/trading_core.py --- ###
# trading/trading_core.py

"""
Modulo: trading_core.py
Descrizione: Integrazione centralizzata per operazioni di trading con TradingView, MetaTrader5 e Interactive Brokers.
Gestisce segnali, esecuzione ordini e monitoraggio stato.
Supporta import opzionali e fallback dinamici.
"""

import logging
from abc import ABC, abstractmethod

# ─── Import dinamici ─────────────────────────────────────────────────────────
try:
    import MetaTrader5 as mt5
except ImportError:
    mt5 = None

try:
    from ib_insync import IB, Stock
except ImportError:
    IB = None
    Stock = None

# ─── Logging Base ────────────────────────────────────────────────────────────
logging.basicConfig(level=logging.INFO)

# ─── Interfaccia Trading Generale ─────────────────────────────────────────────
class TradingInterface(ABC):
    @abstractmethod
    def connect(self): pass

    @abstractmethod
    def execute_order(self, symbol: str, action: str, quantity: float): pass

    @abstractmethod
    def get_status(self) -> str: pass

# ─── TradingView ──────────────────────────────────────────────────────────────
class TradingViewInterface(TradingInterface):
    def connect(self):
        logging.info("✅ TradingView: Nessuna connessione richiesta (webhook o scraping).")

    def execute_order(self, symbol: str, action: str, quantity: float):
        logging.info(f"📡 Segnale da TradingView: {action.upper()} {quantity} {symbol}")

    def get_status(self) -> str:
        return "✔️ TradingView operativo (webhook)"

# ─── MetaTrader5 ──────────────────────────────────────────────────────────────
class MetaTraderInterface(TradingInterface):
    def connect(self):
        if mt5 and mt5.initialize():
            logging.info("✅ Connessione MT5 avviata.")
        else:
            logging.warning("⚠️ MT5 non disponibile o inizializzazione fallita.")

    def execute_order(self, symbol: str, action: str, quantity: float):
        if not mt5:
            return logging.error("❌ MT5 non disponibile.")
        try:
            type_order = mt5.ORDER_TYPE_BUY if action.lower() == "buy" else mt5.ORDER_TYPE_SELL
            request = {
                "action": mt5.TRADE_ACTION_DEAL,
                "symbol": symbol,
                "volume": quantity,
                "type": type_order,
                "price": mt5.symbol_info_tick(symbol).ask,
                "deviation": 10,
                "magic": 234000,
                "comment": "Mercurius∞ Order",
                "type_time": mt5.ORDER_TIME_GTC,
                "type_filling": mt5.ORDER_FILLING_IOC,
            }
            result = mt5.order_send(request)
            logging.info(f"📈 Ordine MT5 eseguito: {result}")
        except Exception as e:
            logging.error(f"❌ Errore invio ordine MT5: {e}")

    def get_status(self) -> str:
        return "🔗 MT5: connesso" if mt5 and mt5.initialize() else "🚫 MT5: non connesso"

# ─── Interactive Brokers (IBKR) ───────────────────────────────────────────────
class IBKRInterface(TradingInterface):
    def __init__(self):
        self.ib = IB() if IB else None

    def connect(self):
        if self.ib:
            try:
                self.ib.connect("127.0.0.1", 7497, clientId=1)
                logging.info("✅ Connessione IBKR attiva.")
            except Exception as e:
                logging.error(f"❌ Errore IBKR: {e}")
        else:
            logging.warning("⚠️ IB_insync non disponibile.")

    def execute_order(self, symbol: str, action: str, quantity: float):
        if not self.ib:
            return logging.error("❌ IB non inizializzato.")
        try:
            stock = Stock(symbol, "SMART", "USD")
            order_type = "BUY" if action.lower() == "buy" else "SELL"
            self.ib.qualifyContracts(stock)
            order = self.ib.marketOrder(order_type, quantity)
            trade = self.ib.placeOrder(stock, order)
            logging.info(f"📊 IBKR Ordine: {order_type} {quantity} {symbol}")
            return trade
        except Exception as e:
            logging.error(f"❌ Errore ordine IBKR: {e}")

    def get_status(self) -> str:
        return "🔗 IBKR: connesso" if self.ib and self.ib.isConnected() else "🚫 IBKR: disconnesso"

### --- trainer/self_trainer.py --- ###
# trainer/self_trainer.py
"""
Modulo: self_trainer.py
Descrizione: Addestramento self-supervised a partire dalle esperienze accumulate.
"""

from memory.long_term_memory import LongTermMemory
import openai
import os
from pathlib import Path

class SelfTrainer:
    def __init__(self, model_name="gpt-3.5-turbo"):
        self.memory = LongTermMemory()
        self.model = model_name
        openai.api_key = os.getenv("OPENAI_API_KEY")

    def build_prompt(self, experiences):
        prompt = "Sei un assistente AI che migliora le proprie strategie di trading.\n"
        prompt += "Ecco le ultime esperienze:\n"
        for exp in experiences[-10:]:
            prompt += f"- Profit: {exp['result']['profit']}, Qty: {exp['trade']['quantity']}\n"
        prompt += "\nSuggerisci tre modi per migliorare la strategia."
        return prompt

    def train_once(self, save_to: Path | None = None):
        data = self.memory.get_all()
        if not data:
            return "Nessuna esperienza."
        prompt = self.build_prompt(data)
        try:
            resp = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3,
            )
            advice = resp["choices"][0]["message"]["content"]
            if save_to:
                save_to.write_text(advice, encoding="utf-8")
            return advice
        except Exception as e:
            return f"⚠️ Training error: {e}"

### --- trainer/trainer_trigger.py --- ###
# trainer/trainer_trigger.py
"""
Modulo: trainer_trigger.py
Descrizione: Innesca SelfTrainer quando ci sono suff. nuove esperienze o in orario schedulato.
"""

import time
import threading
from pathlib import Path
from modules.experience.experience_memory import ExperienceMemory
from trainer.self_trainer import SelfTrainer

class TrainerTrigger:
    def __init__(self, exp_memory: ExperienceMemory, check_interval=600, min_new_exp=25):
        self.exp_memory = exp_memory
        self.check_interval = check_interval
        self.min_new_exp = min_new_exp
        self.trainer = SelfTrainer()
        self._last_count = 0
        threading.Thread(target=self._loop, daemon=True).start()

    def _loop(self):
        while True:
            current_count = len(self.exp_memory.store.get_all())
            if current_count - self._last_count >= self.min_new_exp:
                print("🛠️ TrainerTrigger: Nuove esperienze sufficienti, avvio training...")
                advice = self.trainer.train_once(save_to=Path("logs/latest_strategy_advice.md"))
                print(f"📚 Suggerimenti strategici:\n{advice}\n")
                self._last_count = current_count
            time.sleep(self.check_interval)

### --- update_project_tree.py --- ###
import os
from pathlib import Path

# File extensions to include
EXTENSIONS = {'.py', '.json', '.yaml', '.yml', '.md', '.toml', '.txt'}

ROOT_DIR = Path(__file__).resolve().parent
OUTPUT_FILE = ROOT_DIR / 'project_tree'

def should_include(path: Path) -> bool:
    """Return True if file should be included in the project tree."""
    if '.git' in path.parts:
        return False
    return path.is_file() and path.suffix.lower() in EXTENSIONS

def collect_files(root: Path):
    return sorted(p for p in root.rglob('*') if should_include(p))

def build_tree(files):
    lines = []
    for file_path in files:
        rel = file_path.relative_to(ROOT_DIR)
        lines.append(f"### --- {rel.as_posix()} --- ###")
        try:
            content = file_path.read_text(encoding='utf-8')
        except Exception:
            content = file_path.read_text(encoding='utf-8', errors='ignore')
        lines.append(content.rstrip('\n'))
        lines.append('')
    return '\n'.join(lines) + '\n'

def main():
    files = collect_files(ROOT_DIR)
    tree_content = build_tree(files)
    OUTPUT_FILE.write_text(tree_content, encoding='utf-8')

if __name__ == '__main__':
    main()

### --- updater/__init__.py --- ###


### --- updater/auto_updater.py --- ###
# updater/auto_updater.py
"""
Modulo: auto_updater.py
Descrizione: Aggiorna Mercurius∞ da remoto (GitHub) o da pacchetto tar/zip.
• Scarica la nuova versione
• Esegue migrazioni (requirements, db)
• Riavvia il processo principale
"""

import subprocess
import sys
from pathlib import Path
from typing import Literal, Optional
from analytics.behavior_logger import BehaviorLogger

logger = BehaviorLogger()


class AutoUpdater:
    def __init__(self, repo_url: str, branch: str = "main"):
        self.repo_url = repo_url
        self.branch = branch
        self.repo_dir = Path(".").resolve()

    # ---------- public ----------
    def update(self, source: Literal["git", "package"] = "git", pkg_file: Optional[str] = None):
        if source == "git":
            return self._pull_git()
        if source == "package" and pkg_file:
            return self._extract_package(pkg_file)
        raise ValueError("Sorgente update non valida.")

    # ---------- internal ----------
    def _pull_git(self):
        cmd = ["git", "pull", self.repo_url, self.branch]
        res = subprocess.run(cmd, cwd=self.repo_dir, text=True, capture_output=True)
        logger.log("auto_update", {"method": "git", "stdout": res.stdout, "stderr": res.stderr})
        if res.returncode == 0:
            self._post_update()
            return "✅ Update da Git completato."
        return f"❌ Git pull error: {res.stderr}"

    def _extract_package(self, pkg_file: str):
        import tarfile, zipfile, shutil, tempfile

        tmp = Path(tempfile.mkdtemp())
        if pkg_file.endswith(".tar.gz"):
            with tarfile.open(pkg_file) as tar:
                tar.extractall(tmp)
        elif pkg_file.endswith(".zip"):
            with zipfile.ZipFile(pkg_file) as zf:
                zf.extractall(tmp)
        else:
            return "Formato pacchetto non supportato."

        # Copia sopra il codice
        for item in tmp.iterdir():
            target = self.repo_dir / item.name
            if target.exists():
                shutil.rmtree(target, ignore_errors=True)
            shutil.move(item, target)
        logger.log("auto_update", {"method": "package", "file": pkg_file})
        self._post_update()
        return "✅ Update da package completato."

    def _post_update(self):
        subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements.txt", "-q"])
        logger.log("auto_update", {"action": "deps_installed"})

### --- utils/config_loader.py --- ###
"""
config_loader.py
================
Carica la configurazione da file YAML (mock per ora).
"""

def load_config(path):
    """
    Mock del caricamento configurazione.
    In un sistema reale, caricherebbe da YAML/JSON.
    """
    return {
        "symbols": ["AAPL", "TSLA", "GOOG"],
        "base_trade_qty": 100,
        "min_confidence": 0.55,
        "retrain_threshold": 0.65
    }

### --- utils/environment.py --- ###
"""
Modulo: environment.py
Responsabilità: Caricare e gestire le variabili di ambiente per Mercurius∞
Autore: Mercurius∞ Engineer Mode
"""

import os
from dotenv import load_dotenv

class Environment:
    """
    Carica il file .env e fornisce accesso centralizzato alle variabili di ambiente.
    """

    def __init__(self, dotenv_path: str = ".env"):
        self.loaded = False
        self.dotenv_path = dotenv_path
        self.load_environment()

    def load_environment(self):
        """
        Carica le variabili da .env nel sistema.
        """
        if os.path.exists(self.dotenv_path):
            load_dotenv(dotenv_path=self.dotenv_path)
            self.loaded = True
        else:
            raise FileNotFoundError(f"File .env non trovato in {self.dotenv_path}")

    def get(self, key: str, default=None):
        """
        Recupera una variabile d'ambiente.
        """
        return os.getenv(key, default)

    def get_openai_config(self) -> dict:
        return {
            "use_openai": self.get("USE_OPENAI") == "1",
            "api_key": self.get("OPENAI_API_KEY"),
            "chat_model": self.get("OPENAI_CHAT_MODEL"),
            "embed_model": self.get("OPENAI_EMBED_MODEL")
        }

    def get_web_monitor_credentials(self) -> dict:
        return {
            "user": self.get("WM_USER"),
            "password": self.get("WM_PASS")
        }

    def get_mcp_config(self) -> dict:
        return {
            "token": self.get("MCP_TOKEN"),
            "introspect_url": self.get("MCP_INTROSPECT_URL")
        }

    def get_mercurius_api_key(self) -> str:
        return self.get("MERCURIUS_API_KEY")

    def get_run_mode(self) -> str:
        """Restituisce la modalità operativa di AION."""
        return self.get("AION_RUN_MODE", "dialogic-autonomous")

### --- utils/logger.py --- ###
"""
logger.py
=========
Configurazione logging per il sistema Mercurius∞.
"""

import logging

def setup_logger(name="MercuriusLogger"):
    logger = logging.getLogger(name)
    if not logger.hasHandlers():
        logger.setLevel(logging.DEBUG)
        ch = logging.StreamHandler()
        ch.setLevel(logging.DEBUG)
        formatter = logging.Formatter('[%(asctime)s] %(levelname)s - %(message)s')
        ch.setFormatter(formatter)
        logger.addHandler(ch)
    return logger

def get_file_logger(name="MercuriusFileLogger", filename="mercurius.log"):
    logger = logging.getLogger(name)
    if not logger.hasHandlers():
        logger.setLevel(logging.INFO)
        fh = logging.FileHandler(filename)
        formatter = logging.Formatter('[%(asctime)s] %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        logger.addHandler(fh)
    return logger

### --- utils/telemetry.py --- ###
"""
Modulo: telemetry.py
Responsabilità: Raccolta telemetria interna (risorse, moduli, stato sistema)
Autore: Mercurius∞ Engineer Mode
"""

import psutil
import platform
import os
import time
from typing import Dict


class Telemetry:
    """
    Fornisce dati interni sullo stato del sistema e delle risorse.
    """

    @staticmethod
    def system_info() -> Dict:
        return {
            "platform": platform.system(),
            "platform_version": platform.version(),
            "architecture": platform.machine(),
            "cpu_count": psutil.cpu_count(),
            "memory_total_MB": round(psutil.virtual_memory().total / (1024 ** 2), 2),
        }

    @staticmethod
    def current_usage() -> Dict:
        mem = psutil.virtual_memory()
        return {
            "cpu_percent": psutil.cpu_percent(interval=0.5),
            "memory_used_MB": round(mem.used / (1024 ** 2), 2),
            "memory_percent": mem.percent,
            "active_processes": len(psutil.pids()),
            "uptime_sec": int(time.time() - psutil.boot_time())
        }

    @staticmethod
    def process_info(pid: int = os.getpid()) -> Dict:
        p = psutil.Process(pid)
        return {
            "pid": pid,
            "name": p.name(),
            "status": p.status(),
            "cpu_percent": p.cpu_percent(interval=0.5),
            "memory_MB": round(p.memory_info().rss / (1024 ** 2), 2),
            "threads": p.num_threads()
        }

### --- vision/__init__.py --- ###
from .ocr_module import extract_text_from_image

__all__ = ["extract_text_from_image"]

### --- vision/capture.py --- ###
# vision/capture.py

"""
Modulo: capture.py
Descrizione: Acquisizione video da IP Webcam per Mercurius∞. Utilizza OpenCV per estrarre frame in tempo reale.
"""

import cv2
import numpy as np
from typing import Optional


def get_frame_from_ip(ip_url: str) -> Optional[np.ndarray]:
    """
    Recupera un frame dall'indirizzo IP di una webcam.
    """
    cap = cv2.VideoCapture(ip_url)
    if not cap.isOpened():
        print("❌ Impossibile connettersi alla webcam IP.")
        return None

    ret, frame = cap.read()
    cap.release()

    if not ret:
        print("⚠️ Nessun frame catturato.")
        return None

    return frame

### --- vision/image_vision.py --- ###
# vision/image_vision.py

"""
Modulo: image_vision.py
Descrizione: Analisi di immagini statiche con OCR per l'estrazione di testo e concetti visuali.
Usa pytesseract per lettura OCR e OpenCV per preprocessing.
"""

import pytesseract
import cv2
from typing import List


class ImageVision:
    def __init__(self):
        pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"  # Aggiorna se necessario

    def read_text_from_image(self, image_path: str) -> str:
        """
        Estrae il testo da un'immagine tramite OCR.
        """
        try:
            image = cv2.imread(image_path)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            text = pytesseract.image_to_string(gray)
            return text.strip()
        except Exception as e:
            return f"[ERRORE OCR]: {e}"

    def extract_labels(self, image_path: str) -> List[str]:
        """
        Placeholder per estensione con modello YOLO/Vision per rilevamento oggetti.
        """
        return ["[analisi visiva non implementata]"]

### --- vision/ip_webcam_vision.py --- ###
"""YOLO based detection from IP webcam stream."""
import cv2
from vision.object_vision import ObjectVision

class IPWebcamVision(ObjectVision):
    def start_stream(self, ip_url: str):
        cap = cv2.VideoCapture(ip_url)
        if not cap.isOpened():
            raise RuntimeError("Cannot open IP camera")
        print("📡 Streaming IP webcam... press 'q' to quit")
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            results = self.model(frame, verbose=False)[0]
            annotated = self.box_annotator.annotate(
                scene=frame,
                detections=results.boxes
            )
            cv2.imshow("Mercurius∞ IP Cam", annotated)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        cap.release()
        cv2.destroyAllWindows()

### --- vision/object_vision.py --- ###
# vision/object_vision.py

"""
Modulo: object_vision.py
Descrizione: Riconoscimento oggetti in tempo reale da webcam con YOLOv8.
"""

import cv2
import supervision as sv
from ultralytics import YOLO


class ObjectVision:
    def __init__(self, model_path="yolov8n.pt"):
        self.model = YOLO(model_path)
        self.box_annotator = sv.BoxAnnotator(thickness=2, text_thickness=1, text_scale=0.5)

    def start_detection(self, camera_index=0):
        cap = cv2.VideoCapture(camera_index)
        if not cap.isOpened():
            raise RuntimeError("Camera non accessibile.")

        print("🎥 Avvio rilevamento oggetti YOLOv8... Premi 'q' per uscire.")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            results = self.model(frame, verbose=False)[0]
            detections = sv.Detections.from_ultralytics(results)
            labels = [f"{c} {s:.2f}" for c, s in zip(results.names.values(), results.boxes.conf.cpu().numpy())]

            annotated = self.box_annotator.annotate(scene=frame, detections=detections, labels=labels)
            cv2.imshow("Mercurius∞ Vision", annotated)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

    def contextual_reaction(self, detected_items: list) -> str:
        if "person" in detected_items:
            return "👁️ Persona rilevata. Inizio monitoraggio ambientale."
        elif "keyboard" in detected_items:
            return "⌨️ Attività utente rilevata. Modalità lavoro attiva."
        else:
            return "🔍 Nessun oggetto prioritario rilevato."

### --- vision/ocr_module.py --- ###
"""
Modulo: ocr_module.py
Descrizione: Estrae testo da immagini tramite OCR (Tesseract o alternativa).
"""

try:
    import pytesseract
    from PIL import Image
except ImportError:
    raise ImportError("Modulo OCR non installato: usa `pip install pytesseract pillow`")

def extract_text_from_image(image_path: str) -> str:
    """
    Estrae il testo da un'immagine (jpg, png) usando OCR.
    """
    try:
        img = Image.open(image_path)
        text = pytesseract.image_to_string(img, lang='ita')  # o 'eng' se preferisci
        return text.strip()
    except Exception as e:
        return f"[❌ Errore OCR]: {str(e)}"

### --- vision/ocr_reader.py --- ###
# vision/ocr_reader.py

"""
Modulo: ocr_reader.py
Descrizione: Estrazione testi da immagini o webcam tramite OCR (Tesseract).
Supporta JPEG, PNG, flussi video.
"""

import pytesseract
import cv2


class OCRReader:
    def __init__(self):
        pass

    def read_text_from_image(self, path: str) -> str:
        img = cv2.imread(path)
        return pytesseract.image_to_string(img, lang="ita+eng")

    def read_from_camera(self, camera_index=0):
        cap = cv2.VideoCapture(camera_index)
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            text = pytesseract.image_to_string(frame)
            print(f"[OCR] {text.strip()}")
            cv2.imshow("OCR Live", frame)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        cap.release()
        cv2.destroyAllWindows()

### --- vision/voice_trigger.py --- ###
# voice/voice_trigger.py

"""
Modulo: voice_trigger.py
Descrizione: Attivazione vocale tramite parola chiave "Hey Mercurius" utilizzando STT.
"""

import speech_recognition as sr


def listen_for_trigger(trigger_word: str = "hey mercurius") -> bool:
    """
    Ascolta il microfono per attivazione vocale.
    """
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    with mic as source:
        print("🎙️ Ascolto in corso... (parola chiave: 'Hey Mercurius')")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)

    try:
        text = recognizer.recognize_google(audio).lower()
        print(f"🗣️ Rilevato: {text}")
        return trigger_word in text
    except sr.UnknownValueError:
        print("⚠️ Audio non riconosciuto.")
    except sr.RequestError:
        print("❌ Errore nel servizio di riconoscimento.")

    return False

### --- vision/yolo_handler.py --- ###
# vision/yolo_handler.py

"""
Modulo: yolo_handler.py
Descrizione: Riconoscimento oggetti con YOLOv5/YOLOv8 tramite OpenCV per Mercurius∞.
"""

from typing import List
import torch
import numpy as np

# Caricamento modello YOLO (richiede modello pre-addestrato disponibile localmente)
try:
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', trust_repo=True)
except Exception as e:
    print("⚠️ Errore nel caricamento del modello YOLO:", e)
    model = None


def detect_objects(image: np.ndarray) -> List[str]:
    """
    Rileva oggetti in un'immagine e restituisce le etichette.
    """
    if model is None:
        return []

    results = model(image)
    labels = results.pandas().xyxy[0]['name'].tolist()
    return labels

### --- voice/README.md --- ###
# 🎙️ Modulo Vocale – Attivazione

Gestisce input vocali e hotword per l'attivazione GENESIS.

## Componenti

- `activation_hook.py`: listener per "Hey Mercurius, attiva GENESIS"

### --- voice/__init__.py --- ###


### --- voice/coqui_tts.py --- ###
# voice/coqui_tts.py

"""
Modulo: coqui_tts.py
Descrizione: Sintesi vocale offline con Coqui TTS.
"""

### --- voice/elevenlabs_tts.py --- ###
# voice/elevenlabs_tts.py

"""
Modulo: elevenlabs_tts.py
Descrizione: Voce naturale con API ElevenLabs – stile Jarvis.
"""

import requests
import os

class ElevenLabsTTS:
    def __init__(self, api_key=None):
        self.api_key = api_key or os.getenv("ELEVENLABS_API_KEY")

    def speak(self, text: str, voice_id="EXAVITQu4vr4xnSDxMaL"):
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        headers = {
            "xi-api-key": self.api_key,
            "Content-Type": "application/json"
        }
        json_data = {
            "text": text,
            "model_id": "eleven_monolingual_v1",
            "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
        }
        response = requests.post(url, json=json_data, headers=headers)
        with open("output_11labs.wav", "wb") as f:
            f.write(response.content)

### --- voice/engine/coqui_tts.py --- ###
class CoquiTTS:
    def __init__(self):
        self.name = "CoquiTTS"

    def speak(self, phrase: str) -> str:
        return f"[{self.name}] Audio generato per: {phrase}"

### --- voice/engine/elevenlabs_tts.py --- ###
class ElevenLabsTTS:
    def __init__(self):
        self.name = "ElevenLabs"

    def synthesize(self, text: str, voice: str = "Jarvis") -> str:
        return f"[{self.name}] Sintesi vocale: '{text}' con voce {voice}"

### --- voice/engine/whisper_stt.py --- ###
class WhisperSTT:
    def __init__(self):
        self.name = "Whisper"

    def transcribe(self, audio_path: str) -> str:
        return f"[{self.name}] Trascrizione simulata del file: {audio_path}"

### --- voice/nari_tts.py --- ###
# voice/nari_tts.py

"""
Modulo: nari_tts.py
Descrizione: Sintesi vocale con il modello Nari Dia TTS.
"""

import soundfile as sf
from dia.model import Dia

class NariDiaTTS:
    def __init__(self, model_name="nari-labs/Dia-1.6B"):
        self.model = Dia.from_pretrained(model_name)

    def speak(self, text: str, output_path="output.wav"):
        output = self.model.generate(text)
        sf.write(output_path, output, 44100)

### --- voice/stt.py --- ###
# voice/stt.py

"""
Modulo: stt.py
Descrizione: Riconoscimento vocale da microfono in testo utilizzando SpeechRecognition (Google STT).
"""

import speech_recognition as sr


def transcribe_audio() -> str:
    """
    Converte l'audio acquisito da microfono in testo.
    """
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    with mic as source:
        print("🎧 In ascolto...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)

    try:
        text = recognizer.recognize_google(audio, language="it-IT")
        print(f"📝 Riconosciuto: {text}")
        return text
    except sr.UnknownValueError:
        return "[Voce non riconosciuta]"
    except sr.RequestError:
        return "[Errore nel riconoscimento vocale]"

### --- voice/tts.py --- ###
# voice/tts.py (aggiornato)

"""
Modulo: tts.py
Descrizione: Sintesi vocale con fallback a gTTS se pyttsx3 non disponibile.
"""

try:
    import pyttsx3
    ENGINE = pyttsx3.init()
    USE_PYTTS = True
except ImportError:
    from gtts import gTTS
    import os
    USE_PYTTS = False

