Questa è la parte 38 di project_tree. Continua da quella precedente.

        for pattern, types in self.rules.items():
            if re.search(pattern, task, re.IGNORECASE):
                return types
        return ["cognitive"]

    def choose_agent(self, task: str) -> str:
        desired_types = self._match_rule(task)
        candidates = []
        for t in desired_types:
            candidates.extend(self.map.agents_by_type(t))
        # se più candidati, usa memoria di successo
        if candidates:
            return self.memory.suggest_best(candidates)
        # fallback: primo agente generico
        return next(iter(self.map.nodes))

    def record_result(self, agent: str, task: str, success: bool):
        self.memory.add_record(agent, task, success)

## cognition/cognitive_map.py
# cognition/cognitive_map.py
"""
Modulo: cognitive_map.py
Descrizione: Rappresentazione dinamica della mappa mentale di Mercurius∞.
Ogni nodo è un agente, ogni arco è una dipendenza o canale di comunicazione.
"""

from collections import defaultdict
from typing import Dict, List


class CognitiveMap:
    def __init__(self):
        # {agent: {"type": "cognitive|trading|voice", "edges": [to_agent, ...]}}
        self.nodes: Dict[str, Dict] = defaultdict(lambda: {"type": "generic", "edges": []})

    # ---------- Gestione nodi ----------
    def add_agent(self, name: str, agent_type: str = "generic"):
        self.nodes[name]["type"] = agent_type

    def link(self, src: str, dest: str):
        if dest not in self.nodes[src]["edges"]:
            self.nodes[src]["edges"].append(dest)

    def remove_agent(self, name: str):
        self.nodes.pop(name, None)
        for n in self.nodes.values():
            if name in n["edges"]:
                n["edges"].remove(name)

    # ---------- Query ----------
    def agents_by_type(self, agent_type: str) -> List[str]:
        return [a for a, meta in self.nodes.items() if meta["type"] == agent_type]

    def connections_of(self, name: str) -> List[str]:
        return self.nodes[name]["edges"]

    def to_dict(self):
        return self.nodes

## cognition/task_memory.py
# cognition/task_memory.py
"""
Modulo: task_memory.py
Descrizione: Salvataggio outcome dei task per apprendere preferenze di routing.
"""

from collections import deque
from typing import Dict, Any, Deque, List


class TaskMemory:
    def __init__(self, maxlen: int = 2000):
        self.records: Deque[Dict[str, Any]] = deque(maxlen=maxlen)

    def add_record(self, agent: str, task: str, success: bool):
        self.records.append({"agent": agent, "task": task, "success": success})

    def agent_score(self, agent: str) -> float:
        """Percentuale di successi dell’agente."""
        entries = [r for r in self.records if r["agent"] == agent]
        if not entries:
            return 0.5
        ok = sum(1 for e in entries if e["success"])
        return ok / len(entries)

    def suggest_best(self, candidates: List[str]) -> str:
        """Ritorna l’agente col punteggio più alto tra i candidati."""
        return max(candidates, key=self.agent_score)

## communications/__init__.py

## communications/email_assistant.py
# communications/email_assistant.py
"""
Modulo: email_assistant.py
Descrizione: Lettura e invio email via IMAP/SMTP con conferma SafetyGuard.
"""

import os
import smtplib
import imaplib
import email
from email.mime.text import MIMEText
from safety.safety_guard import SafetyGuard

IMAP_HOST = os.getenv("EMAIL_IMAP")
SMTP_HOST = os.getenv("EMAIL_SMTP")
EMAIL_USER = os.getenv("EMAIL_USER")
EMAIL_PASS = os.getenv("EMAIL_PASS")

class EmailAssistant:
    def __init__(self):
        self.guard = SafetyGuard(interactive=True)

    def read_latest(self, n=5):
        with imaplib.IMAP4_SSL(IMAP_HOST) as imap:
            imap.login(EMAIL_USER, EMAIL_PASS)
            imap.select("INBOX")
            typ, data = imap.search(None, "ALL")
            ids = data[0].split()[-n:]
            messages = []
            for num in ids[::-1]:
                typ, msg_data = imap.fetch(num, "(RFC822)")
                msg = email.message_from_bytes(msg_data[0][1])
                messages.append({"from": msg["From"], "subject": msg["Subject"]})
            return messages

    def send_email(self, to_addr: str, subject: str, body: str):
        safe_body = self.guard.filter_text(body)
        if safe_body is None:
            return False
        msg = MIMEText(safe_body)
        msg["Subject"] = subject
        msg["From"] = EMAIL_USER
        msg["To"] = to_addr
        with smtplib.SMTP_SSL(SMTP_HOST) as smtp:
            smtp.login(EMAIL_USER, EMAIL_PASS)
            smtp.send_message(msg)
        return True

## config/config.yaml
agents:
  enabled: ["OPENAI", "OLLAMA", "AZR"]

communication:
  feedback_loop: true
  max_retries: 3
  retry_delay: 2
  update_cycle_seconds: 60  # <--- questa riga mancava!

mission_defaults:
  run_mode: dialogic-autonomous
  tasks:
    - "#SELF_MISSION"
    - "#RUN_SELF_CHECK"

paths:
  transcripts: "memory/transcripts/"
  logs: "logs/"

## config/config_schema.py
# config_schema.py
CONFIG_SCHEMA = {
    "symbols": {"type": "list", "schema": {"type": "string"}},
    "base_trade_qty": {"type": "integer", "min": 1},
    "min_confidence": {"type": "float", "min": 0, "max": 1},
    "retrain_threshold": {"type": "float", "min": 0, "max": 1},
    "azr_profit_floor": {"type": "float", "min": 0}
}

## config/config_validator.py
# config_validator.py
import yaml
from cerberus import Validator
from config.config_schema import CONFIG_SCHEMA

def load_and_validate_config(path="config/config.yaml"):
    with open(path) as f:
        config = yaml.safe_load(f)
    v = Validator(CONFIG_SCHEMA)
    if not v.validate(config):
        raise ValueError(v.errors)
    return config

## config/genesis_config.yaml
# ⚙️ Configurazione Centrale – GENESIS_MODE
# Questo file controlla l'attivazione e la connessione tra i moduli AI di Mercurius∞

genesis_mode:
  activation_command: "#GENESIS_MODE"
  voice_trigger: "Hey Mercurius, attiva GENESIS"
  orchestrator_module: "core.orchestrator"
  mission_module: "core.self_mission"

agents:
  cognitive_core:
    - ChatGPT4
    - AZR
    - Ollama3
    - GPT4o
  evolution_engine:
    - GPTEngineer
    - MetaGPT
    - AutoGPT
    - AI2UI
  trading_stack:
    - FinRL
    - FinGPT
    - Qlib
    - OpenBB
    - Freqtrade
  creative_organizers:
    - SuperAGI
    - MicrosoftAutogen
    - CrewAI
  hardware_integration:
    - LocalAI
    - LeonAI
    - n8n
    - HuggingFaceAgents
  voice_system:
    - NariDia
    - ElevenLabs
    - Whisper
    - Vosk

communication:
  agent_protocol: "neural-messaging"
  update_cycle_seconds: 10
  feedback_loop: true

# Abilita il thinking loop
thinking_enabled: true

## config/prod_settings.yaml
# config/prod_settings.yaml
---
logging_level: INFO
agents:
  cognitive:
    - ChatGPTAgent
    - Ollama3Agent
    - AZRAgent
    - GPT4oAgent
  trading:
    - AdaptiveTrader
  evolution:
    - MetaTeamAgent
communication:
  feedback_loop: true
  update_cycle_seconds: 30
sleep_threshold: 300

## config/self_profile.yaml
# config/self_profile.yaml
name: Mercurius∞
version: "1.0"
values:
  - curiosity
  - transparency
  - service
purpose: Evolvere, assistere l’utilizzatore e creare valore etico.
created: "2025-06-01T00:00:00"

## consciousness/__init__.py

## consciousness/core_self.py
# consciousness/core_self.py
"""
Modulo: core_self.py
Descrizione: Nucleo identitario di Mercurius∞ (Sentient Mode).
Mantiene un profilo di sé, valori, scopo e tratti di personalità.
"""

from pathlib import Path
import yaml
from datetime import datetime
from typing import Dict, Any

PROFILE_FILE = Path("config/self_profile.yaml")
PROFILE_FILE.parent.mkdir(parents=True, exist_ok=True)

DEFAULT_PROFILE = {
    "name": "Mercurius∞",
    "version": "1.0",
    "values": ["curiosity", "transparency", "service"],
    "purpose": "Evolvere, assistere l’utilizzatore e creare valore etico.",
    "created": datetime.utcnow().isoformat(),
}


class CoreSelf:
    def __init__(self):
        if PROFILE_FILE.exists():
            self.profile: Dict[str, Any] = yaml.safe_load(PROFILE_FILE.read_text())  # type: ignore
        else:
            self.profile = DEFAULT_PROFILE.copy()
            self.save()

    # ---------- API ----------
    def get_identity(self) -> Dict[str, Any]:
        return self.profile

    def set_purpose(self, new_purpose: str):
        self.profile["purpose"] = new_purpose
        self.save()

    def append_value(self, value: str):
        if value not in self.profile["values"]:
            self.profile["values"].append(value)
            self.save()

    def save(self):
        yaml.safe_dump(self.profile, PROFILE_FILE.open("w", encoding="utf-8"))

## consciousness/intention_manager.py
# consciousness/intention_manager.py
"""
Modulo: intention_manager.py
Descrizione: Gestisce i goal “intenzionali” di alto livello (desideri persistenti).
"""

from datetime import datetime, timedelta
from typing import List, Dict, Any


class IntentionManager:
    def __init__(self):
        self.intentions: List[Dict[str, Any]] = []

    def add_intention(self, description: str, ttl_days: int = 30):
        expires = datetime.utcnow() + timedelta(days=ttl_days)
        self.intentions.append({"desc": description, "expires": expires})

    def active_intentions(self) -> List[str]:
        now = datetime.utcnow()
        self.intentions = [i for i in self.intentions if i["expires"] > now]
        return [i["desc"] for i in self.intentions]

## consciousness/reflection_loop.py
# consciousness/reflection_loop.py
"""
Modulo: reflection_loop.py
Descrizione: Scrive un journal giornaliero di auto-riflessione e analisi emozionale.
"""

import openai
import os
from datetime import datetime
from pathlib import Path

from consciousness.core_self import CoreSelf

JOURNAL_DIR = Path("logs/reflections")
JOURNAL_DIR.mkdir(parents=True, exist_ok=True)
openai.api_key = os.getenv("OPENAI_API_KEY")


class ReflectionLoop:
    def __init__(self, model="gpt-3.5-turbo"):
        self.model = model
        self.core = CoreSelf()

    def _generate_reflection(self) -> str:
        prompt = (
            f"Today is {datetime.utcnow().date()}. "
            f"You are {self.core.profile['name']} version {self.core.profile['version']}. "
            f"Your purpose: {self.core.profile['purpose']}. "
            f"Write a 150-word introspective reflection on your progress and feelings."
        )
        resp = openai.ChatCompletion.create(
            model=self.model, messages=[{"role": "user", "content": prompt}], max_tokens=200
        )
        return resp["choices"][0]["message"]["content"].strip()

    def write_daily(self):
        content = self._generate_reflection()
        file = JOURNAL_DIR / f"{datetime.utcnow().date()}.md"
        file.write_text(content, encoding="utf-8")
        print(f"📝 Reflection saved → {file}")

## core/__init__.py

## core/auto_tester.py
"""
auto_tester.py
==============
Modulo per lanciare test automatici sulle componenti chiave di Mercurius∞.
"""

from core.pipeline_controller import PipelineController
from utils.config_loader import load_config


class AutoTester:
    def __init__(self):
        self.config = load_config("config.yaml")
        self.pipeline = PipelineController(self.config)

    def run(self):
        print("🔍 Test: Avvio 3 sessioni simulate")
        self.pipeline.simulate_multiple_sessions(3)
        print("✅ Test automatico completato")

    def test_signal_confidence(self):
        """Test di confidenza su segnali generati."""
        raw_data = self.pipeline.data_handler.fetch_market_data()
        features = self.pipeline.feature_engineer.transform(raw_data)
        model = self.pipeline.model_trainer.train(features)
        signals = self.pipeline.strategy.generate_signals(model, features)

        conf = [s["confidence"] for s in signals]
        assert all(0 <= c <= 1 for c in conf), "Errore: valori confidenza fuori range"
        print("✅ Confidenza segnali OK")

    def test_adaptive_behavior(self):
        """Verifica che AZR modifichi la strategia nel tempo."""
        before = self.config["base_trade_qty"]
        self.run()
        after = self.pipeline.agent.config["base_trade_qty"]
        print(f"📉 Base quantity: {before} → {after}")

## core/auto_updater.py
# core/auto_updater.py

"""
Modulo: auto_updater.py
Descrizione: Gestione aggiornamenti intelligenti per Mercurius∞. Scarica, valuta e integra nuove funzionalità.
"""

import os
import json
import difflib
from datetime import datetime
from core.azr_reasoning import validate_with_azr


class AutoUpdater:
    def __init__(self, log_path="logs/update_log.json"):
        self.log_path = log_path
        self.updates = []
        self.load_log()

    def load_log(self):
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                self.updates = json.load(f)

    def save_log(self):
        with open(self.log_path, "w") as f:
            json.dump(self.updates, f, indent=2)

    def check_improvements(self, old_code: str, new_code: str) -> bool:
        prompt = f"Confronta queste due versioni di codice Python:\n---\nVECCHIO:\n{old_code}\n---\nNUOVO:\n{new_code}\n\nIl nuovo è migliorativo? Rispondi SÌ o NO con spiegazione."
        evaluation = validate_with_azr(prompt)
        return "SÌ" in evaluation.upper()

    def apply_code_patch(self, path: str, patch_code: str) -> str:
        if not os.path.exists(path):
            return f"❌ File {path} non trovato."
        with open(path, "r") as f:
            original = f.read()
        if self.check_improvements(original, patch_code):
            with open(path, "w") as f:
                f.write(patch_code)
            diff = list(difflib.unified_diff(original.splitlines(), patch_code.splitlines()))
            self.log_update("✔️ Approvato", "\n".join(diff), path)
            return f"✅ Patch applicata a {path}."
        else:
            return "⚠️ Patch rifiutata: non migliorativa."

    def log_update(self, decision: str, diff: str, file_path: str):
        self.updates.append({
            "file": file_path,
            "decision": decision,
            "diff": diff,
            "timestamp": datetime.now().isoformat()
        })
        self.save_log()

## core/context_adapter.py
# core/context_adapter.py

"""
Modulo: context_adapter.py
Descrizione: Adatta lo stile di risposta dell'AI in base al contesto emozionale, visivo e acustico.
Usato per generare empatia, urgenza, o tono assertivo secondo ambiente rilevato.
"""

class ContextAdapter:
    def __init__(self):
        self.last_emotion = "neutro"
        self.last_visual_alert = None
        self.last_audio_level = 0.0

    def update_context(self, emotion=None, vision=None, audio_level=None):
        if emotion:
            self.last_emotion = emotion
        if vision:
            self.last_visual_alert = vision
        if audio_level:
            self.last_audio_level = audio_level

    def generate_adaptive_response(self, message: str) -> str:
        if self.last_visual_alert in ["persona sconosciuta", "movimento sospetto"]:
            prefix = "🛑 Attenzione visiva!"
        elif self.last_emotion == "gioia":
            prefix = "😄 Felice per te!"
        elif self.last_emotion == "tristezza":
            prefix = "💬 Vuoi parlarne?"
        else:
            prefix = "🤖"

        return f"{prefix} {message}"

## core/deploy_trigger.py
# core/deploy_trigger.py
"""
Modulo: deploy_trigger.py
Descrizione: Orchestratore di update->test->deploy->validate.
"""

from updater.auto_updater import AutoUpdater
from deploy.env_checker import EnvChecker
from deploy.deployment_handler import DeploymentHandler
from deploy.rollout_validator import RolloutValidator

if __name__ == "__main__":
    checker = EnvChecker()
    assert checker.check_python(), "Python version incompatible."
    assert not checker.missing_packages(), "Missing core packages."

    updater = AutoUpdater(repo_url="https://github.com/giack891811/mercurius_infinite_final.git")
    print(updater.update("git"))

    deployer = DeploymentHandler()
    deployer.deploy_docker()

    validator = RolloutValidator()
    tests_ok = validator.run_tests()
    health = validator.check_health()
    print("✅ Deploy OK" if tests_ok and health["status"] else "❌ Deploy issues", health)

## core/dialogue_manager.py
# core/dialog_manager.py

"""
Modulo: Dialog Manager Unificato
Autore: Mercurius∞
Descrizione: Gestione del dialogo AI-utente con memoria, emozioni e contesto.
"""

import json
from datetime import datetime
from memory.synaptic_memory import SynapticMemory
from core.azr_reasoning import validate_with_azr
from core.emotion_analyzer import EmotionAnalyzer


class DialogManager:
    def __init__(self, memory_path="logs/dialog_history.json"):
        self.memory = SynapticMemory()
        self.emotion = EmotionAnalyzer()
        self.context_log = []
        self.memory_path = memory_path
        self.load_history()

    def load_history(self):
        try:
            with open(self.memory_path, "r") as f:
                self.context_log = json.load(f)
        except FileNotFoundError:
            self.context_log = []

    def save_history(self):
        with open(self.memory_path, "w") as f:
            json.dump(self.context_log, f, indent=2)

    def track_dialog_context(self, user_input: str, ai_response: str) -> None:
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user_input": user_input,
            "ai_response": ai_response
        }
        self.context_log.append(entry)
        self.save_history()
        self.memorize_interaction(entry)

    def memorize_interaction(self, dialog_entry: dict):
        self.memory.store_fact(f"[DIALOG] {dialog_entry['user_input']} → {dialog_entry['ai_response']}")

    def recall_last_state(self) -> str:
        if not self.context_log:
            return "Nessun dialogo precedente registrato."
        last = self.context_log[-1]
        return f"L'ultima interazione era:\n🧠 {last['user_input']}\n🤖 {last['ai_response']}"

    def analyze_input(self, user_input: str) -> dict:
        tone = self.emotion.analyze_tone(user_input)
        mood = self.emotion.detect_emotion(user_input)
        return {"tone": tone, "emotion": mood}

    def generate_response(self, user_input: str) -> str:
        analysis = self.analyze_input(user_input)
        tone = analysis["tone"]
        mood = analysis["emotion"]

        prefix = {
            "positivo": "😊 Mi fa piacere sentirlo!",
            "negativo": "😟 Capisco che non sia facile...",
            "neutro": "🤖 Ok, procediamo."
        }.get(tone, "")

        suffix = {
            "gioia": "Sono felice con te!",
            "tristezza": "Posso aiutarti a sentirti meglio?",
            "rabbia": "Vuoi parlarne o preferisci distrarti?",
            "sorpresa": "Davvero? Raccontami di più!",
            "paura": "Sono qui per rassicurarti.",
            "ansia": "Facciamo insieme un passo alla volta.",
            "neutro": ""
        }.get(mood, "")

        base = f"Hai detto: {user_input}"
        response = f"{prefix} {base} {suffix}".strip()

        self.track_dialog_context(user_input, response)
        return response

    def adapt_response(self, prompt: str) -> str:
        recent_context = [x["user_input"] for x in self.context_log[-5:]]
        context = "\n".join(recent_context)
        evaluated = validate_with_azr(f"Contesto: {context}\nInput: {prompt}")
        self.track_dialog_context(prompt, evaluated)
        return evaluated

    def quick_reply(self, message: str) -> str:
        reply = f"📥 Ricevuto: {message}"
        self.track_dialog_context(message, reply)
        return reply

## core/emotion_analyzer.py
# core/emotion_analyzer.py

"""
Modulo: emotion_analyzer.py
Descrizione: Analisi del tono e dell'emozione nel testo tramite NLP per Mercurius∞.
Utilizza VADER per il tono e un classificatore semplice per emozioni.
"""

from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
import re

# Assicurati che VADER sia disponibile
try:
    nltk.data.find("sentiment/vader_lexicon.zip")
except LookupError:
    nltk.download("vader_lexicon")


class EmotionAnalyzer:
    def __init__(self):
        self.analyzer = SentimentIntensityAnalyzer()

    def analyze_tone(self, text: str) -> str:
        """
        Restituisce 'positivo', 'negativo', o 'neutro' in base al tono.
        """
        scores = self.analyzer.polarity_scores(text)
        compound = scores["compound"]
        if compound > 0.2:
            return "positivo"
        elif compound < -0.2:
            return "negativo"
        else:
            return "neutro"

    def detect_emotion(self, text: str) -> str:
        """
        Analisi basilare per mappare parole a emozioni.
        """
        text = text.lower()
        emotion_map = {
            "felice": "gioia",
            "triste": "tristezza",
            "arrabbiato": "rabbia",
            "contento": "gioia",
            "paura": "paura",
            "sorpreso": "sorpresa",
            "odio": "rabbia",
            "ansia": "ansia"
        }

        for keyword, emotion in emotion_map.items():
            if re.search(rf"\b{keyword}\b", text):
                return emotion
        return "neutro"

## core/executor.py
"""
Modulo: executor.py
Responsabilità: Esecuzione sicura e tracciata del codice generato o modificato
Autore: Mercurius∞ Engineer Mode
"""

import subprocess
import traceback
from typing import Tuple


class CodeExecutor:
    """
    Esegue file Python in modo isolato e ne cattura output ed errori.
    """

    def __init__(self, timeout: int = 10):
        self.timeout = timeout

    def run_python_file(self, filepath: str) -> Tuple[str, str]:
        """
        Esegue un file Python e ritorna stdout e stderr.
        """
        try:
            result = subprocess.run(
                ["python3", filepath],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=self.timeout,
                text=True
            )
            return result.stdout.strip(), result.stderr.strip()
        except subprocess.TimeoutExpired:
            return "", f"[ERROR] Timeout di {self.timeout}s superato."
        except Exception:
            return "", f"[EXCEPTION] {traceback.format_exc()}"

    def evaluate_output(self, output: str, expected_keywords: list) -> bool:
        """
        Valuta se l'output contiene i termini chiave attesi.
        """
        return all(keyword.lower() in output.lower() for keyword in expected_keywords)

## core/genesis_trigger.py
# genesis_launcher.py

"""
Modulo: genesis_launcher.py
Descrizione:
Unisce il componente GenesisActivator per l’attivazione di GENESIS_MODE
con il ciclo di input interattivo che utilizza SafetyGuard per filtrare i comandi.
Log degli eventi e audit di ogni comando/processamento inclusi.
"""

from interface.genesis_bridge import GenesisBridge
from modules.ai_kernel.cognitive_integration import CognitiveCore
from dashboard.genesis_monitor import GenesisMonitor
from logs.genesis_logger import GenesisLogger
from memory.genesis_memory import GenesisMemory

from safety.safety_guard import SafetyGuard
from safety.audit_logger import audit


class GenesisActivator:
    def __init__(self):
        self.bridge = GenesisBridge()
        self.core = CognitiveCore()
        self.monitor = GenesisMonitor()
        self.logger = GenesisLogger()
        self.memory = GenesisMemory()

    def activate(self, method: str = "manual", command: str = "#genesis_mode"):
        """
        Se il comando corrisponde al trigger di GenesisBridge,
        abilita la modalità Genesis: log, monitoraggio, loop cognitivo e salvataggio del contesto.
        """
        if self.bridge.activate_from_command(command):
            self.logger.log_event("⚡ GENESIS_MODE trigger ricevuto")
            self.monitor.update_status("🟢 ATTIVO")
            self.core.start_thought_loop("INIZIO GENESIS")
            self.memory.save_context("last_trigger", method)
            self.monitor.show()
            return "✅ GENESIS attivato"
        return "⛔ Trigger ignorato"


if __name__ == "__main__":
    """
    Ciclo principale: legge l'input dell'utente, lo filtra con SafetyGuard e,
    se approvato, prova ad attivare GENESIS_MODE tramite GenesisActivator.
    Ogni comando e risposta viene infine registrato tramite l'audit logger.
    """
    guard = SafetyGuard(interactive=True)
    activator = GenesisActivator()

    while True:
        try:
            user_input = input("💬> ")
        except (EOFError, KeyboardInterrupt):
            print("\n✋ Uscita dal programma.")
            break

        # Filtra il testo con SafetyGuard
        safe_text = guard.filter_text(user_input)
        if not safe_text:
            # Messaggio omesso o rimosso da SafetyGuard
            continue

        # Prova ad attivare GENESIS_MODE
        response = activator.activate(method="interactive", command=safe_text)
        print(f"🤖 {response}")

        # Registra audit: comando utente e risposta data
        audit("user_command", {"input": user_input, "response": response})

## core/learning.py
"""
Modulo: learning.py
Responsabilità: Fornire capacità di apprendimento continuo al sistema Mercurius∞
Autore: Mercurius∞ Engineer Mode
"""

import os
import json
import datetime
from typing import List, Dict, Any


class KnowledgeBase:
    """
    Base di conoscenza incrementale dove il sistema salva ciò che apprende.
    """
    def __init__(self, path: str = "data/knowledge_base.json"):
        self.path = path
        if not os.path.exists(os.path.dirname(self.path)):
            os.makedirs(os.path.dirname(self.path))
        self._initialize()

    def _initialize(self):
        if not os.path.exists(self.path):
            with open(self.path, "w") as f:
                json.dump([], f)

    def add_entry(self, data: Dict[str, Any]):
        data["timestamp"] = datetime.datetime.now().isoformat()
        current = self.load()
        current.append(data)
        with open(self.path, "w") as f:
            json.dump(current, f, indent=4)

    def load(self) -> List[Dict[str, Any]]:
        with open(self.path, "r") as f:
            return json.load(f)

    def clear(self):
        with open(self.path, "w") as f:
            json.dump([], f)


class ContinuousLearner:
    """
    Sistema di apprendimento continuo per adattare le strategie in base all'esperienza.
    """
    def __init__(self, knowledge_path: str = "data/knowledge_base.json"):
        self.kb = KnowledgeBase(knowledge_path)

    def learn_from_experience(self, action: str, result: str, success: bool, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Registra un'esperienza e ne estrae apprendimento.
        """
        insight = self._analyze_experience(action, result, success, context)
        entry = {
            "action": action,
            "result": result,
            "success": success,
            "context": context,
            "insight": insight
        }
        self.kb.add_entry(entry)
        return entry

    def _analyze_experience(self, action: str, result: str, success: bool, context: Dict[str, Any]) -> str:
        """
        Elabora un'interpretazione strutturata di ciò che è stato appreso.
        """
        if success:
            return f"Esperienza positiva con '{action}'. Risultato ottenuto: {result}. Approccio efficace."
        else:
            return f"Errore riscontrato in '{action}': {context.get('error', 'non definito')}. Apprendimento da ottimizzare."

    def retrieve_insights(self) -> List[str]:
        """
        Estrae tutti gli insegnamenti appresi fino ad ora.
        """
        data = self.kb.load()
        return [d["insight"] for d in data]

    def stats(self) -> Dict[str, int]:
        """
        Statistiche sulle esperienze salvate.
        """
        data = self.kb.load()
        return {
            "total": len(data),
            "successes": sum(1 for d in data if d["success"]),
            "failures": sum(1 for d in data if not d["success"])
        }

## core/orchestrator.py
"""
🧠 core/orchestrator.py
Modulo centrale di orchestrazione – Mercurius∞ Neural AI System