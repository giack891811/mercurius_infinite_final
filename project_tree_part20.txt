Questa √® la parte 20 di project_tree. Continua da quella precedente.

purpose: Evolvere, assistere l‚Äôutilizzatore e creare valore etico.
created: "2025-06-01T00:00:00"

## consciousness/__init__.py

## consciousness/core_self.py
# consciousness/core_self.py
"""
Modulo: core_self.py
Descrizione: Nucleo identitario di Mercurius‚àû (Sentient Mode).
Mantiene un profilo di s√©, valori, scopo e tratti di personalit√†.
"""

from pathlib import Path
import yaml
from datetime import datetime
from typing import Dict, Any

PROFILE_FILE = Path("config/self_profile.yaml")
PROFILE_FILE.parent.mkdir(parents=True, exist_ok=True)

DEFAULT_PROFILE = {
    "name": "Mercurius‚àû",
    "version": "1.0",
    "values": ["curiosity", "transparency", "service"],
    "purpose": "Evolvere, assistere l‚Äôutilizzatore e creare valore etico.",
    "created": datetime.utcnow().isoformat(),
}


class CoreSelf:
    def __init__(self):
        if PROFILE_FILE.exists():
            self.profile: Dict[str, Any] = yaml.safe_load(PROFILE_FILE.read_text())  # type: ignore
        else:
            self.profile = DEFAULT_PROFILE.copy()
            self.save()

    # ---------- API ----------
    def get_identity(self) -> Dict[str, Any]:
        return self.profile

    def set_purpose(self, new_purpose: str):
        self.profile["purpose"] = new_purpose
        self.save()

    def append_value(self, value: str):
        if value not in self.profile["values"]:
            self.profile["values"].append(value)
            self.save()

    def save(self):
        yaml.safe_dump(self.profile, PROFILE_FILE.open("w", encoding="utf-8"))

## consciousness/intention_manager.py
# consciousness/intention_manager.py
"""
Modulo: intention_manager.py
Descrizione: Gestisce i goal ‚Äúintenzionali‚Äù di alto livello (desideri persistenti).
"""

from datetime import datetime, timedelta
from typing import List, Dict, Any


class IntentionManager:
    def __init__(self):
        self.intentions: List[Dict[str, Any]] = []

    def add_intention(self, description: str, ttl_days: int = 30):
        expires = datetime.utcnow() + timedelta(days=ttl_days)
        self.intentions.append({"desc": description, "expires": expires})

    def active_intentions(self) -> List[str]:
        now = datetime.utcnow()
        self.intentions = [i for i in self.intentions if i["expires"] > now]
        return [i["desc"] for i in self.intentions]

## consciousness/reflection_loop.py
# consciousness/reflection_loop.py
"""
Modulo: reflection_loop.py
Descrizione: Scrive un journal giornaliero di auto-riflessione e analisi emozionale.
"""

import openai
import os
from datetime import datetime
from pathlib import Path

from consciousness.core_self import CoreSelf

JOURNAL_DIR = Path("logs/reflections")
JOURNAL_DIR.mkdir(parents=True, exist_ok=True)
openai.api_key = os.getenv("OPENAI_API_KEY")


class ReflectionLoop:
    def __init__(self, model="gpt-3.5-turbo"):
        self.model = model
        self.core = CoreSelf()

    def _generate_reflection(self) -> str:
        prompt = (
            f"Today is {datetime.utcnow().date()}. "
            f"You are {self.core.profile['name']} version {self.core.profile['version']}. "
            f"Your purpose: {self.core.profile['purpose']}. "
            f"Write a 150-word introspective reflection on your progress and feelings."
        )
        resp = openai.ChatCompletion.create(
            model=self.model, messages=[{"role": "user", "content": prompt}], max_tokens=200
        )
        return resp["choices"][0]["message"]["content"].strip()

    def write_daily(self):
        content = self._generate_reflection()
        file = JOURNAL_DIR / f"{datetime.utcnow().date()}.md"
        file.write_text(content, encoding="utf-8")
        print(f"üìù Reflection saved ‚Üí {file}")

## core/__init__.py

## core/auto_tester.py
"""
auto_tester.py
==============
Modulo per lanciare test automatici sulle componenti chiave di Mercurius‚àû.
"""

from core.pipeline_controller import PipelineController
from utils.config_loader import load_config


class AutoTester:
    def __init__(self):
        self.config = load_config("config.yaml")
        self.pipeline = PipelineController(self.config)

    def run(self):
        print("üîç Test: Avvio 3 sessioni simulate")
        self.pipeline.simulate_multiple_sessions(3)
        print("‚úÖ Test automatico completato")

    def test_signal_confidence(self):
        """Test di confidenza su segnali generati."""
        raw_data = self.pipeline.data_handler.fetch_market_data()
        features = self.pipeline.feature_engineer.transform(raw_data)
        model = self.pipeline.model_trainer.train(features)
        signals = self.pipeline.strategy.generate_signals(model, features)

        conf = [s["confidence"] for s in signals]
        assert all(0 <= c <= 1 for c in conf), "Errore: valori confidenza fuori range"
        print("‚úÖ Confidenza segnali OK")

    def test_adaptive_behavior(self):
        """Verifica che AZR modifichi la strategia nel tempo."""
        before = self.config["base_trade_qty"]
        self.run()
        after = self.pipeline.agent.config["base_trade_qty"]
        print(f"üìâ Base quantity: {before} ‚Üí {after}")

## core/auto_updater.py
# core/auto_updater.py

"""
Modulo: auto_updater.py
Descrizione: Gestione aggiornamenti intelligenti per Mercurius‚àû. Scarica, valuta e integra nuove funzionalit√†.
"""

import os
import json
import difflib
from datetime import datetime
from core.azr_reasoning import validate_with_azr


class AutoUpdater:
    def __init__(self, log_path="logs/update_log.json"):
        self.log_path = log_path
        self.updates = []
        self.load_log()

    def load_log(self):
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                self.updates = json.load(f)

    def save_log(self):
        with open(self.log_path, "w") as f:
            json.dump(self.updates, f, indent=2)

    def check_improvements(self, old_code: str, new_code: str) -> bool:
        prompt = f"Confronta queste due versioni di codice Python:\n---\nVECCHIO:\n{old_code}\n---\nNUOVO:\n{new_code}\n\nIl nuovo √® migliorativo? Rispondi S√å o NO con spiegazione."
        evaluation = validate_with_azr(prompt)
        return "S√å" in evaluation.upper()

    def apply_code_patch(self, path: str, patch_code: str) -> str:
        if not os.path.exists(path):
            return f"‚ùå File {path} non trovato."
        with open(path, "r") as f:
            original = f.read()
        if self.check_improvements(original, patch_code):
            with open(path, "w") as f:
                f.write(patch_code)
            diff = list(difflib.unified_diff(original.splitlines(), patch_code.splitlines()))
            self.log_update("‚úîÔ∏è Approvato", "\n".join(diff), path)
            return f"‚úÖ Patch applicata a {path}."
        else:
            return "‚ö†Ô∏è Patch rifiutata: non migliorativa."

    def log_update(self, decision: str, diff: str, file_path: str):
        self.updates.append({
            "file": file_path,
            "decision": decision,
            "diff": diff,
            "timestamp": datetime.now().isoformat()
        })
        self.save_log()

## core/context_adapter.py
# core/context_adapter.py

"""
Modulo: context_adapter.py
Descrizione: Adatta lo stile di risposta dell'AI in base al contesto emozionale, visivo e acustico.
Usato per generare empatia, urgenza, o tono assertivo secondo ambiente rilevato.
"""

class ContextAdapter:
    def __init__(self):
        self.last_emotion = "neutro"
        self.last_visual_alert = None
        self.last_audio_level = 0.0

    def update_context(self, emotion=None, vision=None, audio_level=None):
        if emotion:
            self.last_emotion = emotion
        if vision:
            self.last_visual_alert = vision
        if audio_level:
            self.last_audio_level = audio_level

    def generate_adaptive_response(self, message: str) -> str:
        if self.last_visual_alert in ["persona sconosciuta", "movimento sospetto"]:
            prefix = "üõë Attenzione visiva!"
        elif self.last_emotion == "gioia":
            prefix = "üòÑ Felice per te!"
        elif self.last_emotion == "tristezza":
            prefix = "üí¨ Vuoi parlarne?"
        else:
            prefix = "ü§ñ"

        return f"{prefix} {message}"

## core/deploy_trigger.py
# core/deploy_trigger.py
"""
Modulo: deploy_trigger.py
Descrizione: Orchestratore di update->test->deploy->validate.
"""

from updater.auto_updater import AutoUpdater
from deploy.env_checker import EnvChecker
from deploy.deployment_handler import DeploymentHandler
from deploy.rollout_validator import RolloutValidator

if __name__ == "__main__":
    checker = EnvChecker()
    assert checker.check_python(), "Python version incompatible."
    assert not checker.missing_packages(), "Missing core packages."

    updater = AutoUpdater(repo_url="https://github.com/giack891811/mercurius_infinite_final.git")
    print(updater.update("git"))

    deployer = DeploymentHandler()
    deployer.deploy_docker()

    validator = RolloutValidator()
    tests_ok = validator.run_tests()
    health = validator.check_health()
    print("‚úÖ Deploy OK" if tests_ok and health["status"] else "‚ùå Deploy issues", health)

## core/dialogue_manager.py
# core/dialog_manager.py

"""
Modulo: Dialog Manager Unificato
Autore: Mercurius‚àû
Descrizione: Gestione del dialogo AI-utente con memoria, emozioni e contesto.
"""

import json
from datetime import datetime
from memory.synaptic_memory import SynapticMemory
from core.azr_reasoning import validate_with_azr
from core.emotion_analyzer import EmotionAnalyzer


class DialogManager:
    def __init__(self, memory_path="logs/dialog_history.json"):
        self.memory = SynapticMemory()
        self.emotion = EmotionAnalyzer()
        self.context_log = []
        self.memory_path = memory_path
        self.load_history()

    def load_history(self):
        try:
            with open(self.memory_path, "r") as f:
                self.context_log = json.load(f)
        except FileNotFoundError:
            self.context_log = []

    def save_history(self):
        with open(self.memory_path, "w") as f:
            json.dump(self.context_log, f, indent=2)

    def track_dialog_context(self, user_input: str, ai_response: str) -> None:
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user_input": user_input,
            "ai_response": ai_response
        }
        self.context_log.append(entry)
        self.save_history()
        self.memorize_interaction(entry)

    def memorize_interaction(self, dialog_entry: dict):
        self.memory.store_fact(f"[DIALOG] {dialog_entry['user_input']} ‚Üí {dialog_entry['ai_response']}")

    def recall_last_state(self) -> str:
        if not self.context_log:
            return "Nessun dialogo precedente registrato."
        last = self.context_log[-1]
        return f"L'ultima interazione era:\nüß† {last['user_input']}\nü§ñ {last['ai_response']}"

    def analyze_input(self, user_input: str) -> dict:
        tone = self.emotion.analyze_tone(user_input)
        mood = self.emotion.detect_emotion(user_input)
        return {"tone": tone, "emotion": mood}

    def generate_response(self, user_input: str) -> str:
        analysis = self.analyze_input(user_input)
        tone = analysis["tone"]
        mood = analysis["emotion"]

        prefix = {
            "positivo": "üòä Mi fa piacere sentirlo!",
            "negativo": "üòü Capisco che non sia facile...",
            "neutro": "ü§ñ Ok, procediamo."
        }.get(tone, "")

        suffix = {
            "gioia": "Sono felice con te!",
            "tristezza": "Posso aiutarti a sentirti meglio?",
            "rabbia": "Vuoi parlarne o preferisci distrarti?",
            "sorpresa": "Davvero? Raccontami di pi√π!",
            "paura": "Sono qui per rassicurarti.",
            "ansia": "Facciamo insieme un passo alla volta.",
            "neutro": ""
        }.get(mood, "")

        base = f"Hai detto: {user_input}"
        response = f"{prefix} {base} {suffix}".strip()

        self.track_dialog_context(user_input, response)
        return response

    def adapt_response(self, prompt: str) -> str:
        recent_context = [x["user_input"] for x in self.context_log[-5:]]
        context = "\n".join(recent_context)
        evaluated = validate_with_azr(f"Contesto: {context}\nInput: {prompt}")
        self.track_dialog_context(prompt, evaluated)
        return evaluated

    def quick_reply(self, message: str) -> str:
        reply = f"üì• Ricevuto: {message}"
        self.track_dialog_context(message, reply)
        return reply

## core/emotion_analyzer.py
# core/emotion_analyzer.py

"""
Modulo: emotion_analyzer.py
Descrizione: Analisi del tono e dell'emozione nel testo tramite NLP per Mercurius‚àû.
Utilizza VADER per il tono e un classificatore semplice per emozioni.
"""

from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
import re

# Assicurati che VADER sia disponibile
try:
    nltk.data.find("sentiment/vader_lexicon.zip")
except LookupError:
    nltk.download("vader_lexicon")


class EmotionAnalyzer:
    def __init__(self):
        self.analyzer = SentimentIntensityAnalyzer()

    def analyze_tone(self, text: str) -> str:
        """
        Restituisce 'positivo', 'negativo', o 'neutro' in base al tono.
        """
        scores = self.analyzer.polarity_scores(text)
        compound = scores["compound"]
        if compound > 0.2:
            return "positivo"
        elif compound < -0.2:
            return "negativo"
        else:
            return "neutro"

    def detect_emotion(self, text: str) -> str:
        """
        Analisi basilare per mappare parole a emozioni.
        """
        text = text.lower()
        emotion_map = {
            "felice": "gioia",
            "triste": "tristezza",
            "arrabbiato": "rabbia",
            "contento": "gioia",
            "paura": "paura",
            "sorpreso": "sorpresa",
            "odio": "rabbia",
            "ansia": "ansia"
        }

        for keyword, emotion in emotion_map.items():
            if re.search(rf"\b{keyword}\b", text):
                return emotion
        return "neutro"

## core/executor.py
"""
Modulo: executor.py
Responsabilit√†: Esecuzione sicura e tracciata del codice generato o modificato
Autore: Mercurius‚àû Engineer Mode
"""

import subprocess
import traceback
from typing import Tuple


class CodeExecutor:
    """
    Esegue file Python in modo isolato e ne cattura output ed errori.
    """

    def __init__(self, timeout: int = 10):
        self.timeout = timeout

    def run_python_file(self, filepath: str) -> Tuple[str, str]:
        """
        Esegue un file Python e ritorna stdout e stderr.
        """
        try:
            result = subprocess.run(
                ["python3", filepath],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=self.timeout,
                text=True
            )
            return result.stdout.strip(), result.stderr.strip()
        except subprocess.TimeoutExpired:
            return "", f"[ERROR] Timeout di {self.timeout}s superato."
        except Exception:
            return "", f"[EXCEPTION] {traceback.format_exc()}"

    def evaluate_output(self, output: str, expected_keywords: list) -> bool:
        """
        Valuta se l'output contiene i termini chiave attesi.
        """
        return all(keyword.lower() in output.lower() for keyword in expected_keywords)

## core/genesis_trigger.py
# genesis_launcher.py

"""
Modulo: genesis_launcher.py
Descrizione:
Unisce il componente GenesisActivator per l‚Äôattivazione di GENESIS_MODE
con il ciclo di input interattivo che utilizza SafetyGuard per filtrare i comandi.
Log degli eventi e audit di ogni comando/processamento inclusi.
"""

from interface.genesis_bridge import GenesisBridge
from modules.ai_kernel.cognitive_integration import CognitiveCore
from dashboard.genesis_monitor import GenesisMonitor
from logs.genesis_logger import GenesisLogger
from memory.genesis_memory import GenesisMemory

from safety.safety_guard import SafetyGuard
from safety.audit_logger import audit


class GenesisActivator:
    def __init__(self):
        self.bridge = GenesisBridge()
        self.core = CognitiveCore()
        self.monitor = GenesisMonitor()
        self.logger = GenesisLogger()
        self.memory = GenesisMemory()

    def activate(self, method: str = "manual", command: str = "#genesis_mode"):
        """
        Se il comando corrisponde al trigger di GenesisBridge,
        abilita la modalit√† Genesis: log, monitoraggio, loop cognitivo e salvataggio del contesto.
        """
        if self.bridge.activate_from_command(command):
            self.logger.log_event("‚ö° GENESIS_MODE trigger ricevuto")
            self.monitor.update_status("üü¢ ATTIVO")
            self.core.start_thought_loop("INIZIO GENESIS")
            self.memory.save_context("last_trigger", method)
            self.monitor.show()
            return "‚úÖ GENESIS attivato"
        return "‚õî Trigger ignorato"


if __name__ == "__main__":
    """
    Ciclo principale: legge l'input dell'utente, lo filtra con SafetyGuard e,
    se approvato, prova ad attivare GENESIS_MODE tramite GenesisActivator.
    Ogni comando e risposta viene infine registrato tramite l'audit logger.
    """
    guard = SafetyGuard(interactive=True)
    activator = GenesisActivator()

    while True:
        try:
            user_input = input("üí¨> ")
        except (EOFError, KeyboardInterrupt):
            print("\n‚úã Uscita dal programma.")
            break

        # Filtra il testo con SafetyGuard
        safe_text = guard.filter_text(user_input)
        if not safe_text:
            # Messaggio omesso o rimosso da SafetyGuard
            continue

        # Prova ad attivare GENESIS_MODE
        response = activator.activate(method="interactive", command=safe_text)
        print(f"ü§ñ {response}")

        # Registra audit: comando utente e risposta data
        audit("user_command", {"input": user_input, "response": response})

## core/learning.py
"""
Modulo: learning.py
Responsabilit√†: Fornire capacit√† di apprendimento continuo al sistema Mercurius‚àû
Autore: Mercurius‚àû Engineer Mode
"""

import os
import json
import datetime
from typing import List, Dict, Any


class KnowledgeBase:
    """
    Base di conoscenza incrementale dove il sistema salva ci√≤ che apprende.
    """
    def __init__(self, path: str = "data/knowledge_base.json"):
        self.path = path
        if not os.path.exists(os.path.dirname(self.path)):
            os.makedirs(os.path.dirname(self.path))
        self._initialize()

    def _initialize(self):
        if not os.path.exists(self.path):
            with open(self.path, "w") as f:
                json.dump([], f)

    def add_entry(self, data: Dict[str, Any]):
        data["timestamp"] = datetime.datetime.now().isoformat()
        current = self.load()
        current.append(data)
        with open(self.path, "w") as f:
            json.dump(current, f, indent=4)

    def load(self) -> List[Dict[str, Any]]:
        with open(self.path, "r") as f:
            return json.load(f)

    def clear(self):
        with open(self.path, "w") as f:
            json.dump([], f)


class ContinuousLearner:
    """
    Sistema di apprendimento continuo per adattare le strategie in base all'esperienza.
    """
    def __init__(self, knowledge_path: str = "data/knowledge_base.json"):
        self.kb = KnowledgeBase(knowledge_path)

    def learn_from_experience(self, action: str, result: str, success: bool, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Registra un'esperienza e ne estrae apprendimento.
        """
        insight = self._analyze_experience(action, result, success, context)
        entry = {
            "action": action,
            "result": result,
            "success": success,
            "context": context,
            "insight": insight
        }
        self.kb.add_entry(entry)
        return entry

    def _analyze_experience(self, action: str, result: str, success: bool, context: Dict[str, Any]) -> str:
        """
        Elabora un'interpretazione strutturata di ci√≤ che √® stato appreso.
        """
        if success:
            return f"Esperienza positiva con '{action}'. Risultato ottenuto: {result}. Approccio efficace."
        else:
            return f"Errore riscontrato in '{action}': {context.get('error', 'non definito')}. Apprendimento da ottimizzare."

    def retrieve_insights(self) -> List[str]:
        """
        Estrae tutti gli insegnamenti appresi fino ad ora.
        """
        data = self.kb.load()
        return [d["insight"] for d in data]

    def stats(self) -> Dict[str, int]:
        """
        Statistiche sulle esperienze salvate.
        """
        data = self.kb.load()
        return {
            "total": len(data),
            "successes": sum(1 for d in data if d["success"]),
            "failures": sum(1 for d in data if not d["success"])
        }

## core/orchestrator.py
"""
üß† core/orchestrator.py
Modulo centrale di orchestrazione ‚Äì Mercurius‚àû Neural AI System
Gestisce la rete multi-agente in modalit√† GENESIS con auto-adattamento.
"""

import importlib
import yaml
import time
import threading
from pathlib import Path
import sys
import os
from core.self_tuner import SelfTuner
from core.sleep_monitor import SleepMonitor
from core.thinking_loop import ThinkingLoop
from integrations.bridge_josch import send_command_to_pc
from sensors.sensor_hub import capture_screen_stream, listen_microphone

CONFIG_PATH = Path("config/genesis_config.yaml")

class Orchestrator:
    def __init__(self):
        self.config = self.load_config()
        self.agents = {}
        self.active = False
        self.sleep_monitor = SleepMonitor(idle_threshold=self.config.get("sleep_threshold", 300))
        self.thinking_loop: ThinkingLoop | None = None
        self.multisensorial_enabled = True

    def load_config(self):
        with open('config/config.yaml', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def activate_genesis(self):
        print("‚ö° Attivazione modalit√† GENESIS...")
        self.active = True
        self.load_agents()
        self.start_feedback_loop()
        self.start_sleep_monitor()

        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                cfg = yaml.safe_load(f)
            if cfg.get("thinking_enabled", True):
                self.thinking_loop = ThinkingLoop(CONFIG_PATH)
                self.thinking_loop.start()
                print("üß† Thinking loop attivo.")
        except Exception as e:
            print(f"‚ö†Ô∏è Errore avvio thinking loop: {e}")

        try:
            from modules.vision_audio.note10_jarvis_bridge import start_jarvis_loop
            threading.Thread(target=start_jarvis_loop, daemon=True).start()
            print("üì° Note10+ Bridge attivo ‚Äì In ascolto microfono e comandi vocali.")
        except Exception as e:
            print(f"‚ö†Ô∏è Errore avvio Note10+ Jarvis: {e}")

        try:
            from modules.mobile_flutter.flutter_bridge import start_mobile_ui
            threading.Thread(target=start_mobile_ui, daemon=True).start()
            print("üì± Mobile Jarvis UI attivo.")
        except Exception as e:
            print(f"‚ö†Ô∏è Errore avvio Mobile UI: {e}")



        #REMOTE_EXEC
        try:
            send_command_to_pc("start vscode")
        except Exception as e:
            print(f"‚ö†Ô∏è Errore invio comando PC: {e}")
        if self.multisensorial_enabled:
            try:
                capture_screen_stream()
                listen_microphone()
            except Exception as e:
                print(f"‚ö†Ô∏è Errore avvio sensori: {e}")

        print("‚úÖ GENESIS attiva ‚Äì Rete neurale in esecuzione.")

    def load_agents(self):
        print("üîå Caricamento agenti dalla configurazione...")
        agent_groups = self.config.get("agents", {})
        for group, agent_list in agent_groups.items():
            self.agents[group] = []
            for agent_name in agent_list:
                try:
                    module_path = f"agents.{agent_name.lower()}"
                    agent_module = importlib.import_module(module_path)
                    agent = getattr(agent_module, agent_name)()
                    self.agents[group].append(agent)
                    print(f"üß† Caricato agente: {agent_name} in {group}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Errore caricamento {agent_name}: {e}")

    def start_feedback_loop(self):
        if self.config["communication"]["feedback_loop"]:
            print("üîÅ Avvio feedback loop neurale...")
            threading.Thread(target=self.feedback_cycle, daemon=True).start()
[TRONCATO]

## core/pipeline_controller.py
"""
pipeline_controller.py
=======================
Orchestratore principale delle componenti del sistema Mercurius‚àû.
Permette di avviare cicli completi di analisi, apprendimento e trading
in modalit√† batch, streaming o simulata.
"""

from utils.logger import setup_logger
from data.market_data_handler import MarketDataHandler
from data.feature_engineering import FeatureEngineer
from models.model_trainer import ModelTrainer
from strategies.strategy_executor import StrategyExecutor
from agents.adaptive_trader import AdaptiveTrader
from agents.memory_manager import MemoryManager


class PipelineController:
    def __init__(self, config):
        self.logger = setup_logger("PipelineController")
        self.config = config

        self.memory = MemoryManager(config)
        self.data_handler = MarketDataHandler(config)
        self.feature_engineer = FeatureEngineer(config)
        self.model_trainer = ModelTrainer(config)
        self.strategy = StrategyExecutor(config)
        self.agent = AdaptiveTrader(
            config,
            memory_manager=self.memory,
            model_trainer=self.model_trainer,
            strategy_executor=self.strategy,
        )

    def run_batch_session(self):
        """Esegue un'intera sessione di ciclo batch."""
        self.logger.info("üöÄ Avvio sessione di pipeline Mercurius‚àû")

        raw_data = self.data_handler.fetch_market_data()
        features = self.feature_engineer.transform(raw_data)
        model = self.model_trainer.train(features)
        signals = self.strategy.generate_signals(model, features)
        self.agent.execute_trades(signals)

        self.logger.info("‚úÖ Sessione pipeline completata")

    def simulate_multiple_sessions(self, n=3):
        """Esegue n sessioni simulate consecutive."""
        for i in range(n):
            self.logger.info(f"‚ñ∂Ô∏è Esecuzione sessione simulata {i + 1}/{n}")
            self.run_batch_session()

## core/sandbox_executor.py
"""
Modulo: sandbox_executor.py
Descrizione: Esecuzione sicura, isolata e autoregolata di codice Python generato da Mercurius‚àû.
Include analisi statica, sandboxing con timeout, cattura stdout, e correzione automatica con AZR e LLM.
Autore: Mercurius‚àû AI Engineer
"""

import traceback
import contextlib
import io
import multiprocessing
import os

from modules.llm.azr_reasoner import validate_with_azr 





# ‚îÄ‚îÄ‚îÄ Correzione automatica con LLM esterno (opzionale) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    import openai
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
    OPENAI_READY = bool(OPENAI_API_KEY)
except ImportError:
    openai = None
    OPENAI_READY = False


class SandboxExecutor:
    def __init__(self, timeout_seconds: int = 5):
        self.timeout = timeout_seconds
        self.last_output = ""
        self.last_error = ""

    def static_analysis(self, code: str) -> bool:
        """
        Verifica se il codice √® sintatticamente valido.
        """
        try:
            compile(code, "<sandbox_analysis>", "exec")
            return True
        except SyntaxError:
            return False

    def _execute_code(self, code: str, return_dict):
        """
        Funzione interna per eseguire codice in un processo separato.
        """
        buffer = io.StringIO()
        local_vars = {}
        try:
            with contextlib.redirect_stdout(buffer):
                exec(code, {}, local_vars)
            return_dict["success"] = True
            return_dict["output"] = buffer.getvalue()
        except Exception:
            return_dict["success"] = False
            return_dict["output"] = traceback.format_exc()

    def run_sandboxed(self, code: str) -> dict:
        """
        Esegue codice in un ambiente isolato con timeout.
        """
        manager = multiprocessing.Manager()
        return_dict = manager.dict()

        process = multiprocessing.Process(target=self._execute_code, args=(code, return_dict))
        process.start()
        process.join(self.timeout)

        if process.is_alive():
            process.terminate()
            self.last_error = "‚ùå Timeout: codice troppo lento o bloccato."
            return {"success": False, "output": self.last_error}

        result = return_dict.copy()
        self.last_output = result.get("output", "")
        if not result.get("success"):
            self.last_error = self.last_output
            return {
                "success": False,
                "output": self.last_output,
                "suggested_fix": self.autofix_with_llm(code, self.last_output)
            }
        return result

    def autofix_with_llm(self, code: str, error_msg: str) -> str:
        """
        Prova a correggere il codice errato usando:
        1. AZR Reasoner per correzioni ragionate.
        2. Se disponibile, LLM esterno (es. GPT-4 via OpenAI API).