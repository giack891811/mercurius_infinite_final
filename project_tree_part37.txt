Questa Ã¨ la parte 37 di project_tree. Continua da quella precedente.

fastapi==0.115.12
ffmpy==0.5.0
filelock==3.18.0
fire==0.7.0
flatten-dict==0.4.2
fonttools==4.58.1
fsspec==2025.5.1
future==1.0.0
gitdb==4.0.12
GitPython==3.1.44
gradio==5.32.0
gradio_client==1.10.2
greenlet==3.2.2
groovy==0.1.2
grpcio==1.71.0
h11==0.16.0
httpcore==1.0.9
httpx==0.28.1
huggingface-hub==0.32.3
idna==3.10
imageio==2.37.0
imageio-ffmpeg==0.6.0
importlib_resources==6.5.2
iniconfig==2.1.0
ipython==9.3.0
ipython_pygments_lexers==1.1.1
jedi==0.19.2
Jinja2==3.1.6
jiter==0.10.0
joblib==1.5.1
jsonpatch==1.33
jsonpointer==3.0.0
jsonschema==4.24.0
jsonschema-specifications==2025.4.1
julius==0.2.7
kiwisolver==1.4.8
langchain==0.3.25
langchain-core==0.3.63
langchain-text-splitters==0.3.8
langsmith==0.3.43
lazy_loader==0.4
librosa==0.11.0
llama_cpp_python==0.3.9
llvmlite==0.44.0
lxml==5.4.0
lxml_html_clean==0.4.2
Markdown==3.8
markdown-it-py==3.0.0
markdown2==2.5.3
MarkupSafe==3.0.2
matplotlib==3.10.3
matplotlib-inline==0.1.7
mdurl==0.1.2
-e git+https://github.com/giack891811/mercurius_infinite_final.git@92670b6422489a439fa7e6e9c4a47cdaa4aef3e1#egg=mercurius_infinite
more-itertools==10.7.0
moviepy==2.2.1
mpmath==1.3.0
msgpack==1.1.0
-e git+https://github.com/nari-labs/dia.git@2811af1c5f476b1f49f4744fabf56cf352be21e5#egg=nari_tts
narwhals==1.41.0
networkx==3.5
numba==0.61.2
numpy==1.26.4
openai==1.82.1
openai-whisper==20240930
opencv-python==4.11.0.86
[TRONCATO]

## seleziona_cartella.py
from tkinter import Tk, filedialog

root = Tk()
root.withdraw()  # Nasconde la finestra principale
folder_path = filedialog.askdirectory(title="Seleziona una cartella")

print("ðŸ“ Cartella selezionata:", folder_path)

## setup.py
from setuptools import setup, find_packages

setup(
    name="mercurius-infinite",
    version="1.0.0",
    packages=find_packages(),
    include_package_data=True,
    install_requires=[
        "altair==5.5.0",
        "altgraph==0.17.4",
        "annotated-types==0.7.0",
        "anyio==4.9.0",
        "attrs==25.3.0",
        "blinker==1.9.0",
        "cachetools==5.5.2",
        "certifi==2025.4.26",
        "cffi==1.17.1",
        "charset-normalizer==3.4.2",
        "click==8.2.1",
        "colorama==0.4.6",
        "comtypes==1.4.11",
        "contourpy==1.3.2",
        "cycler==0.12.1",
        "decorator==5.2.1",
        "defusedxml==0.7.1",
        "distro==1.9.0",
        "filelock==3.18.0",
        "fonttools==4.58.1",
        "fsspec==2025.5.1",
        "gitdb==4.0.12",
        "GitPython==3.1.44",
        "h11==0.16.0",
        "httpcore==1.0.9",
        "httpx==0.28.1",
        "huggingface-hub==0.32.3",
        "idna==3.10",
        "imageio==2.37.0",
        "imageio-ffmpeg==0.6.0",
        "Jinja2==3.1.6",
        "jiter==0.10.0",
        "joblib==1.5.1",
        "jsonschema==4.24.0",
        "jsonschema-specifications==2025.4.1",
        "kiwisolver==1.4.8",
        "MarkupSafe==3.0.2",
        "matplotlib==3.10.3",
        "moviepy==2.2.1",
        "mpmath==1.3.0",
        "narwhals==1.41.0",
        "networkx==3.5",
        "numpy==2.2.6",
        "openai==1.82.1",
        "opencv-python==4.11.0.86",
        "packaging==24.2",
        "pandas==2.2.3",
        "pefile==2023.2.7",
        "pillow==11.2.1",
        "proglog==0.1.12",
        "protobuf==6.31.1",
        "psutil==7.0.0",
        "py-cpuinfo==9.0.0",
        "pyarrow==20.0.0",
        "pycparser==2.22",
        "pydantic==2.11.5",
        "pydantic_core==2.33.2",
        "pydeck==0.9.1",
        "pyinstaller==6.13.0",
        "pyinstaller-hooks-contrib==2025.4",
        "pyparsing==3.2.3",
        "pypiwin32==223",
        "PyQt5==5.15.11",
        "PyQt5-Qt5==5.15.2",
        "PyQt5_sip==12.17.0",
        "pytesseract==0.3.13",
        "python-dateutil==2.9.0.post0",
        "python-dotenv==1.1.0",
        "pyttsx3==2.98",
        "pytube==15.0.0",
        "pytz==2025.2",
        "pywin32==310",
        "pywin32-ctypes==0.2.3",
        "PyYAML==6.0.2",
        "referencing==0.36.2",
        "regex==2024.11.6",
        "requests==2.32.3",
        "rpds-py==0.25.1",
        "safetensors==0.5.3",
        "scikit-learn==1.6.1",
        "scipy==1.15.3",
        "sentence-transformers==4.1.0",
        "setuptools==80.9.0",
        "six==1.17.0",
        "smmap==5.0.2",
        "sniffio==1.3.1",
        "sounddevice==0.5.2",
        "SpeechRecognition==3.14.3",
        "srt==3.5.3",
        "streamlit==1.45.1",
        "supervision==0.25.1",
        "sympy==1.14.0",
[TRONCATO]

## start_fullmode.py
def main():
    print("ðŸ” Avvio completo Mercuriusâˆž")
    print("ðŸ§  ModalitÃ  Jarvis+ attiva: Visione, Voce, Dashboard, AI Cognitiva")
    # Avviare sequenze di bootstrap dei moduli AI
    from modules.Neo.trainer_orchestrator import bootstrap_agents
    bootstrap_agents()

if __name__ == "__main__":
    main()

## start_voice_interface.py
"""
Script: start_voice_interface
Funzione: Comunicazione vocale Mercuriusâˆž da file audio nella root.
Autore: Mercuriusâˆž AI Engineer
"""

import os
from modules.voice_bridge.multimodal_controller import MultimodalController
from modules.ai_kernel.agent_core import AgentCore

AUDIO_FILE = "audio_input.wav"  # Assicurati che il file sia nella root!

def ensure_audio_exists(path):
    if not os.path.exists(path):
        print(f"[ERRORE] File audio non trovato: {path}")
        exit(1)

def avvia_interazione_vocale(audio_file):
    ensure_audio_exists(audio_file)

    agente = AgentCore()
    multimodale = MultimodalController()

    print("ðŸŽ™ï¸ Avvio comunicazione vocale...")
    multimodale.listen_and_respond(audio_file, agente.process_input)

if __name__ == "__main__":
    avvia_interazione_vocale(AUDIO_FILE)

## task_manager_cli.py
from modules.task_manager_cli import main

if __name__ == "__main__":
    main()

## test_exp.json
[
  {
    "tags": [
      "unit"
    ],
    "result": "ok",
    "timestamp": "2025-06-01T12:23:47.154527"
  }
]

## .github/workflows/mercurius_ci.yml
# .github/workflows/ci.yml
name: Mercurius CI/CD

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: â¬‡ï¸ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest flake8

      - name: ðŸ” Lint check (flake8)
        run: |
          flake8 . --exclude=.venv

      - name: âœ… Run unit & integration tests
        run: |
          pytest tests/ > test_results.txt
        continue-on-error: true

      - name: ðŸ“¤ Upload test artifacts
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: test_results.txt

      - name: ðŸ³ Build Docker image
        run: docker build -t mercurius:ci .

  deploy-staging:
    needs: build-and-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: â¬‡ï¸ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸš€ Simulated deploy to staging
        run: echo "ðŸš€ Deploying to staging... [Simulazione]"

  refresh-mcp:
    needs: deploy-staging
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ”„ Refresh MCP introspection
        run: echo "ðŸ”„ MCP Introspection Updated"

  generate-colab-notebook:
    needs: refresh-mcp
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“˜ Generate Colab Notebook
        run: echo "ðŸ“˜ Colab notebook generation simulated"

  notify-slack:
    needs: generate-colab-notebook
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“© Slack notification
        run: echo "ðŸ“© Slack message simulation"

  mercurius-autonomous-plan:
    needs: notify-slack
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ§  Run Mercurius Autonomous Action Plan
        run: echo "ðŸ§  Executing Mercurius Autonomous Plan..."

## agents/__init__.py
"""
ðŸ“¦ agents/__init__.py
Modulo inizializzatore per il caricamento dinamico degli agenti AI della rete neurale Mercuriusâˆž
"""

# Placeholder: gli agenti verranno creati come moduli singoli in agents/
# Ogni modulo dovrÃ  contenere una classe con lo stesso nome dell'agente definito in genesis_config.yaml
# Esempio: agents/ChatGPT4.py -> class ChatGPT4:

## agents/adaptive_trader.py
# agents/adaptive_trader.py
"""
adaptive_trader.py
==================
Agente autonomo per esecuzione dinamica di operazioni di trading sulla base
dei segnali ricevuti, stato di memoria, e adattamento esperienziale (AZR).
"""
from modules.experience.azr_analyzer import AZRAnalyzer
from modules.experience.experience_memory import ExperienceMemory

class AdaptiveTrader:
    def __init__(self, config, memory_manager, model_trainer, strategy_executor):
        self.config = config
        self.memory = memory_manager
        self.model_trainer = model_trainer
        self.strategy = strategy_executor
        self.trade_log = []
        self.experience_memory = ExperienceMemory(config)
        self.azr = AZRAnalyzer(self.experience_memory, config)

    def evaluate_signals(self, signals):
        """Valuta i segnali di trading ricevuti in base al contesto corrente."""
        evaluated = []
        for signal in signals:
            confidence = signal.get('confidence', 0.5)
            if confidence > self.config.get("min_confidence", 0.6):
                evaluated.append(signal)
        return evaluated

    def execute_trades(self, signals):
        """Esegue le operazioni basandosi sui segnali validati."""
        valid_signals = self.evaluate_signals(signals)
        for signal in valid_signals:
            trade = {
                "symbol": signal["symbol"],
                "action": signal["action"],
                "quantity": self._calculate_quantity(signal),
                "timestamp": signal.get("timestamp")
            }
            # Simula risultato dell'operazione di trading
            result = self._simulate_trade_result(trade)
            feedback = self._generate_feedback(trade, result)
            # Registra l'esperienza e aggiorna memoria
            self.experience_memory.record_experience(signal, trade, result, feedback)
            self.memory.record_trade(trade)
            self.trade_log.append(trade)
            print(f"Eseguito trade: {trade} â†’ Profit: {result['profit']:.2f}")
        # Dopo aver eseguito i trade, applica eventuali adattamenti (AZR)
        self._adaptive_adjustment()

    def _calculate_quantity(self, signal):
        """Calcola la quantitÃ  da tradare in base al rischio e asset allocation."""
        base_qty = self.config.get("base_trade_qty", 100)
        volatility_factor = signal.get("volatility", 1)
        return int(base_qty / volatility_factor)

    def _simulate_trade_result(self, trade):
        """Mock del risultato di un'operazione (calcolo profitto casuale)."""
        import random
        direction = 1 if trade["action"].upper() == "BUY" else -1
        price_diff = random.uniform(-5, 10) * direction
        return {"profit": round(price_diff * trade["quantity"] * 0.01, 2)}

    def _generate_feedback(self, trade, result):
        """Mock di feedback evolutivo basato sul risultato dell'operazione."""
        return {
            "profit_margin": result["profit"] / (trade["quantity"] + 1),
            "risk_level": trade["quantity"]
        }

    def _adaptive_adjustment(self):
        """Applica AZR per modificare i parametri in base allâ€™esperienza recente."""
        result = self.azr.apply_adaptation()
        # L'adattamento AZR modifica la config in place; notifica eventuali cambiamenti rilevanti
        if result and result.get("decision", {}).get("action") == "decrease_risk":
            new_qty = result["decision"]["new_qty"]
            print(f"ðŸ”„ Adattamento AZR: ridotta base_trade_qty a {new_qty}")

    def get_trade_history(self):
        """Restituisce lo storico delle operazioni eseguite."""
        return self.trade_log

## agents/agent_comm.py
# agents/agent_comm.py

"""
Modulo: agent_comm.py
Descrizione: Gestione della comunicazione tra agenti all'interno della rete Mercuriusâˆž.
Permette lo scambio di messaggi strutturati tra agenti identificati da ID.
"""

from typing import Dict, List
from datetime import datetime

# Simulazione struttura di memorizzazione dei messaggi
MESSAGES: Dict[str, List[Dict]] = {}


def send_message(sender_id: str, receiver_id: str, content: str) -> None:
    """
    Invia un messaggio da un agente a un altro.
    """
    message = {
        "timestamp": datetime.now().isoformat(),
        "from": sender_id,
        "to": receiver_id,
        "content": content
    }
    if receiver_id not in MESSAGES:
        MESSAGES[receiver_id] = []
    MESSAGES[receiver_id].append(message)


def get_messages(agent_id: str) -> List[Dict]:
    """
    Recupera tutti i messaggi ricevuti da un agente.
    """
    return MESSAGES.get(agent_id, [])

## agents/agent_generator.py
# agents/agent_generator.py

"""
Modulo: agent_generator.py
Descrizione: Generazione dinamica di nuovi agenti per Mercuriusâˆž con personalitÃ  e missione specifiche.
"""

from typing import Dict
import uuid


class Agent:
    def __init__(self, name: str, personality: str, mission: str):
        self.id = str(uuid.uuid4())
        self.name = name
        self.personality = personality
        self.mission = mission

    def describe(self) -> Dict:
        return {
            "id": self.id,
            "name": self.name,
            "personality": self.personality,
            "mission": self.mission
        }


def generate_agent(personality: str, mission: str, name: str = "Unnamed Agent") -> Agent:
    """
    Crea un nuovo agente con parametri definiti.
    """
    return Agent(name, personality, mission)

## agents/azr.py
"""AZR reasoning agent."""
from modules.llm.azr_reasoner import AZRAgent

class AZR:
    def __init__(self):
        self.agent = AZRAgent()

    def analyze(self, text: str) -> str:
        return self.agent.analyze(text)

    def neural_feedback(self):
        print("[AZR] feedback cycle active")

## agents/azr_server.py
"""azr_server.py
Modulo FastAPI che espone l'endpoint introspect per il Reasoner AZR.
Utilizzabile da Mercuriusâˆž per sapere se AZR Ã¨ attivo.
"""

from fastapi import FastAPI
import uvicorn

app = FastAPI(title="AZR Server")

@app.get("/introspect")
def introspect():
    return {"status": "AZR is running", "version": "1.0", "agent": "AZR"}

def start_server(host: str = "0.0.0.0", port: int = 4010):
    uvicorn.run("agents.azr_server:app", host=host, port=port, reload=True)

if __name__ == "__main__":
    start_server()

## agents/memory_manager.py
"""
memory_manager.py
=================
Gestione della memoria storica delle operazioni, segnali e parametri per l'adattivitÃ  dell'agente.
"""

class MemoryManager:
    def __init__(self, config):
        self.config = config
        self.trade_memory = []
        self.signal_memory = []
        self.context = {}

    def record_trade(self, trade):
        """Registra un trade eseguito nella memoria storica."""
        self.trade_memory.append(trade)
        self._update_context(trade)

    def record_signal(self, signal):
        """Registra un segnale ricevuto."""
        self.signal_memory.append(signal)

    def _update_context(self, trade):
        """Aggiorna il contesto operativo in base ai trade recenti."""
        symbol = trade["symbol"]
        self.context[symbol] = self.context.get(symbol, 0) + 1

    def get_recent_trades(self, limit=10):
        """Restituisce gli ultimi trade effettuati."""
        return self.trade_memory[-limit:]

    def get_signal_history(self, symbol=None):
        """Restituisce la memoria dei segnali per uno specifico simbolo o tutti."""
        if symbol:
            return [s for s in self.signal_memory if s["symbol"] == symbol]
        return self.signal_memory

    def clear(self):
        """Resetta la memoria."""
        self.trade_memory.clear()
        self.signal_memory.clear()
        self.context.clear()

    def export_summary(self):
        """Ritorna una sintesi dello stato attuale della memoria."""
        return {
            "tot_trades": len(self.trade_memory),
            "tot_signals": len(self.signal_memory),
            "context_symbols": list(self.context.keys())
        }

    def analyze_bias(self):
        """Analizza possibili bias nel comportamento di trading."""
        counts = {}
        for trade in self.trade_memory:
            symbol = trade["symbol"]
            counts[symbol] = counts.get(symbol, 0) + 1
        return sorted(counts.items(), key=lambda x: -x[1])

## agents/ollama.py
"""Ollama local LLM agent."""
import requests
import json

class OLLAMA:
    def __init__(self, url: str = "http://localhost:11434/api/generate", model: str = "llama3"):
        self.url = url
        self.model = model

    def chat(self, prompt: str) -> str:
        data = {"model": self.model, "prompt": prompt}
        try:
            r = requests.post(self.url, headers={"Content-Type": "application/json"}, data=json.dumps(data))
            r.raise_for_status()
            return r.json().get("response", "").strip()
        except Exception as e:
            return f"[Ollama error] {e}"

    def ask(self, prompt: str) -> str:
        return self.chat(prompt)

    def neural_feedback(self):
        print("[Ollama] feedback cycle active")

## agents/openai.py
"""OpenAI agent wrapper for Mercuriusâˆž."""
import os
import openai

class OPENAI:
    def __init__(self, model: str = "gpt-3.5-turbo"):
        self.model = model
        openai.api_key = os.getenv("OPENAI_API_KEY", "")

    def chat(self, prompt: str) -> str:
        try:
            resp = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=200,
            )
            return resp["choices"][0]["message"]["content"].strip()
        except Exception as e:
            return f"[OpenAI error] {e}"

    def neural_feedback(self):
        print("[OpenAI] feedback cycle active")

## agents/azr/azr_supervisor.py
"""
azr_supervisor.py
=================
Controllore strategico per adattamento Mercuriusâˆž basato su esperienze.
"""

from modules.experience.azr_analyzer import AZRAnalyzer
from modules.metrics.performance_metrics import PerformanceMetrics


class AZRSupervisor:
    def __init__(self, agent, experience_memory, config):
        self.agent = agent
        self.memory = experience_memory
        self.config = config
        self.analyzer = AZRAnalyzer(self.memory, config)

    def supervise(self):
        analysis = self.analyzer.analyze_recent_performance()
        suggestion = analysis.get("decision", {})
        if suggestion.get("action") == "decrease_risk":
            new_qty = suggestion["new_qty"]
            self.agent.adjust_strategy({"base_trade_qty": new_qty})
        return analysis

## analytics/__init__.py

## analytics/behavior_logger.py
# analytics/behavior_logger.py
"""
Modulo: behavior_logger.py
Descrizione: Log comportamentale centralizzato per Mercuriusâˆž.
Registra errori, fallback, performance-hit e successi in un file JSONL con TTL.
"""

from pathlib import Path
from datetime import datetime
import json
import hashlib

LOG_FILE = Path("logs/behavior_log.jsonl")
LOG_FILE.parent.mkdir(parents=True, exist_ok=True)


class BehaviorLogger:
    def __init__(self):
        self.file = LOG_FILE

    def log(self, event: str, details: dict):
        entry = {
            "ts": datetime.utcnow().isoformat(),
            "event": event,
            "hash": hashlib.md5(event.encode()).hexdigest()[:6],
            "details": details,
        }
        with self.file.open("a", encoding="utf-8") as f:
            f.write(json.dumps(entry) + "\n")

    def tail(self, n: int = 100):
        if not self.file.exists():
            return []
        return self.file.read_text(encoding="utf-8").splitlines()[-n:]

## analytics/meta_learner.py
# analytics/meta_learner.py
"""
Modulo: meta_learner.py
Descrizione: Analizza il Behavior Log e calcola KPI sulle performance
per suggerire miglioramenti a moduli/parametri.
"""

from collections import Counter
from typing import Dict, Any, List
import json

from analytics.behavior_logger import BehaviorLogger

class MetaLearner:
    def __init__(self):
        self.logger = BehaviorLogger()

    def _load_events(self) -> List[Dict[str, Any]]:
        raw = self.logger.tail(5000)
        return [json.loads(line) for line in raw]

    def kpi(self) -> Dict[str, Any]:
        data = self._load_events()
        total = len(data)
        errors = [e for e in data if e["event"] == "error"]
        successes = [e for e in data if e["event"] == "success"]
        modules = Counter(e["details"].get("module", "unknown") for e in errors)
        return {
            "total_events": total,
            "error_rate": len(errors) / total if total else 0,
            "success_rate": len(successes) / total if total else 0,
            "top_error_modules": modules.most_common(5),
        }

    def recommend(self) -> str:
        kpi = self.kpi()
        if kpi["error_rate"] > 0.2:
            worst = kpi["top_error_modules"][0][0] if kpi["top_error_modules"] else "unknown"
            return f"ðŸ¤– Consiglio: test approfonditi su modulo '{worst}' (errore>20%)."
        return "âœ… Sistema stabile: nessuna azione critica."

## analytics/neuro_optimizer.py
# analytics/neuro_optimizer.py
"""
Modulo: neuro_optimizer.py
Descrizione: Usa MetaLearner + LLM per proporre refactor automatici ai moduli peggiori.
"""

import os
import openai
from pathlib import Path

from analytics.meta_learner import MetaLearner

class NeuroOptimizer:
    def __init__(self, model="gpt-3.5-turbo"):
        self.meta = MetaLearner()
        self.model = model
        openai.api_key = os.getenv("OPENAI_API_KEY")

    def _call_llm(self, prompt: str) -> str:
        resp = openai.ChatCompletion.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800,
        )
        return resp["choices"][0]["message"]["content"]

    def suggest_patch(self) -> dict | None:
        rec = self.meta.recommend()
        if "test approfonditi su modulo" not in rec:
            return None
        module_name = rec.split("'")[1]
        file_path = Path(f"{module_name.replace('.', '/')}.py")
        if not file_path.exists():
            return None
        original_code = file_path.read_text(encoding="utf-8")
        prompt = (
            "Migliora il codice seguente correggendo bug, aggiungendo docstring "
            "e typing. Restituisci il file completo.\n\n"
            f"FILE: {file_path}\n```python\n{original_code}\n```"
        )
        new_code = self._call_llm(prompt)
        return {"path": str(file_path), "code": new_code}

## analytics/self_patch_engine.py
# analytics/self_patch_engine.py
"""
Modulo: self_patch_engine.py
Descrizione: Genera una patch git e crea automaticamente un branch+commit con i
suggerimenti di NeuroOptimizer.
"""

import subprocess
from pathlib import Path
from typing import Optional
from analytics.neuro_optimizer import NeuroOptimizer
from analytics.behavior_logger import BehaviorLogger

class SelfPatchEngine:
    def __init__(self, repo_root: str = "."):
        self.root = Path(repo_root)
        self.optimizer = NeuroOptimizer()
        self.logger = BehaviorLogger()

    def _git(self, *args):
        return subprocess.run(["git", *args], cwd=self.root, capture_output=True, text=True)

    def apply_patch(self) -> Optional[str]:
        suggestion = self.optimizer.suggest_patch()
        if not suggestion:
            print("Nessuna patch suggerita.")
            return None
        path = Path(suggestion["path"])
        branch = f"auto_patch_{path.stem}"
        self._git("checkout", "-B", branch)
        path.write_text(suggestion["code"], encoding="utf-8")
        self._git("add", str(path))
        self._git("commit", "-m", f"ðŸ¤– Auto-patch {path.name} (NeuroOptimizer)")
        self.logger.log("auto_patch", {"path": suggestion["path"]})
        print(f"âœ… Patch applicata su branch {branch}")
        return branch

## cognition/__init__.py

## cognition/agent_router.py
# cognition/agent_router.py
"""
Modulo: agent_router.py
Descrizione: Seleziona l'agente ottimale per un task usando CognitiveMap + TaskMemory.
"""

import re
from typing import Dict

from cognition.cognitive_map import CognitiveMap
from cognition.task_memory import TaskMemory


class AgentRouter:
    def __init__(self, c_map: CognitiveMap, memory: TaskMemory):
        self.map = c_map
        self.memory = memory
        # pattern â†’ lista agent_type preferiti
        self.rules: Dict[str, list[str]] = {
            r"\b(trade|buy|sell)\b": ["trading"],
            r"\b(voice|speak|listen)\b": ["voice"],
            r"\b(debug|validate|logic)\b": ["cognitive"],
        }

    def _match_rule(self, task: str):